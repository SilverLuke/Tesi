{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Data dir: /dati/luca/Uni-Luca/Tesi/progetto/datasets\n",
      " Benchmarks dir: /dati/luca/Uni-Luca/Tesi/progetto/benchmarks\n",
      "    Weights dir: /dati/luca/Uni-Luca/Tesi/progetto/plots/weights\n",
      "Tensorboard dir: /tmp/tensorboard\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from functools import *\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "from keras_tuner import Hyperband, BayesianOptimization, RandomSearch\n",
    "from keras import callbacks as kc\n",
    "\n",
    "from IRESNs_tensorflow.time_series_datasets import *\n",
    "from IRESNs_tensorflow.models import *\n",
    "from benchmarks import *\n",
    "from general_hp import *\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd() + os.sep + os.pardir)\n",
    "\n",
    "DATA_ROOT = os.path.join(PROJECT_ROOT, \"datasets\")\n",
    "TB_ROOT = os.path.join(os.path.abspath(os.sep), \"tmp\", \"tensorboard\")\n",
    "\n",
    "BENCHMARKS_ROOT = os.path.join(PROJECT_ROOT, \"benchmarks\")\n",
    "WEIGHTS_ROOT = os.path.join(PROJECT_ROOT, \"plots\", \"weights\")\n",
    "\n",
    "print(\"       Data dir:\", DATA_ROOT)\n",
    "print(\" Benchmarks dir:\", BENCHMARKS_ROOT)\n",
    "print(\"    Weights dir:\", WEIGHTS_ROOT)\n",
    "print(\"Tensorboard dir:\", TB_ROOT)\n",
    "\n",
    "MAX_EPOCHS = 5000  # Positive Integer. How many epochs the tuner train the model for each trials\n",
    "PATIENCE = 10  # EarlyStopping\n",
    "BENCHMARKS_TRIALS = 10  # How many times do the benchmark. 0 to skip BENCHMARKS\n",
    "MS_VERBOSE = 0\n",
    "\n",
    "hyperparameters = {\n",
    "    'Spectral Radius': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'Input Scaling'  : [0.01, 0.1, 1.],\n",
    "    'Bias Scaling'   : [0.01, 0.1, 1.],\n",
    "    'Inter Scaling'  : [0.0, 0.01, 0.1, 1.],\n",
    "}\n",
    "\n",
    "SKIP = True  # Skip if a model is already tested?\n",
    "OVERWRITE = False  # Redo the model selection for a model?\n",
    "\n",
    "TUNER = \"GridSearch\"\n",
    "TUNER_DESC = \"Libras\"\n",
    "\n",
    "READOUT_ACTIVATION_BINARY = keras.activations.sigmoid\n",
    "LOSS_FUNCTION_BINARY = keras.losses.BinaryCrossentropy()\n",
    "READOUT_ACTIVATION = keras.activations.softmax  # https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "LOSS_FUNCTION = keras.losses.SparseCategoricalCrossentropy()  # https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "\n",
    "if not os.path.exists(TB_ROOT):\n",
    "    os.makedirs(TB_ROOT)\n",
    "\n",
    "TUNER_STRING = TUNER + \".\" + str(MAX_EPOCHS) + \"mt.\" + TUNER_DESC\n",
    "benchmarks = BenchmarksDB(load_path=os.path.join(BENCHMARKS_ROOT, TUNER_STRING + \".json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_seed(names):\n",
    "    dataset_name, class_name, experiment_name, model_name = names\n",
    "    import hashlib\n",
    "    union = dataset_name + class_name + experiment_name + model_name\n",
    "    hashed = hashlib.md5(union.encode('UTF-8'))\n",
    "    seed = int(hashed.hexdigest(), 16) % 4294967295  # limit to 32 bit length value\n",
    "    return seed\n",
    "\n",
    "\n",
    "def model_selection(build_model_fn, hyperparameters, dimensions,\n",
    "                    names, train_set, val_set, verbosity=0):\n",
    "    dataset_name, class_name, experiment_name, model_name = names\n",
    "    x_train, y_train = train_set\n",
    "    x_val, y_val = val_set\n",
    "    tf.random.set_seed(get_seed(names))\n",
    "\n",
    "    set_hps = {}\n",
    "\n",
    "    if model_name == \"ESN\":\n",
    "        set_hps['Spectral Radius'] = hyperparameters['Spectral Radius']\n",
    "        set_hps['Input Scaling'] = hyperparameters['Input Scaling']\n",
    "        set_hps['Bias Scaling'] = hyperparameters['Bias Scaling']\n",
    "    else:\n",
    "        if class_name == \"Single SR Single Input Single Inter\":\n",
    "            set_hps['Spectral Radius'] = hyperparameters['Spectral Radius']\n",
    "            set_hps['Input Scaling'] = hyperparameters['Input Scaling']\n",
    "            set_hps['Inter Scaling'] = hyperparameters['Inter Scaling']\n",
    "            set_hps['Bias Scaling'] = hyperparameters['Bias Scaling']\n",
    "        elif class_name == \"Multiple SR Single Input Single Inter\":\n",
    "            for i in range(dimensions):\n",
    "                set_hps['Spectral Radius ' + str(i)] = hyperparameters['Spectral Radius']\n",
    "            set_hps['Input Scaling'] = hyperparameters['Input Scaling']\n",
    "            set_hps['Inter Scaling'] = hyperparameters['Inter Scaling']\n",
    "            set_hps['Bias Scaling'] = hyperparameters['Bias Scaling']\n",
    "        elif class_name == \"Single SR Multiple Input Single Inter\":\n",
    "            set_hps['Spectral Radius'] = hyperparameters['Spectral Radius']\n",
    "            for i in range(dimensions):\n",
    "                set_hps['Input Scaling ' + str(i)] = hyperparameters['Input Scaling']\n",
    "            set_hps['Inter Scaling'] = hyperparameters['Inter Scaling']\n",
    "            set_hps['Bias Scaling'] = hyperparameters['Bias Scaling']\n",
    "        elif class_name == \"Single SR Single Input Multiple Inter\":\n",
    "            set_hps['Spectral Radius'] = hyperparameters['Spectral Radius']\n",
    "            set_hps['Input Scaling'] = hyperparameters['Input Scaling']\n",
    "            for i in range(dimensions):\n",
    "                set_hps['Inter Scaling ' + str(i)] = hyperparameters['Inter Scaling']\n",
    "            set_hps['Bias Scaling'] = hyperparameters['Bias Scaling']\n",
    "        else:\n",
    "            raise ValueError(\"Unknown Experiment class\")\n",
    "\n",
    "    indices = {key: 0 for key in set_hps.keys()}\n",
    "    iterate = True\n",
    "    iteration = 0\n",
    "    score = [(0, 0)]\n",
    "    best_hps = {}\n",
    "    while iterate:\n",
    "        hp2test = {}\n",
    "        for key, vals in set_hps.items():\n",
    "            hp2test[key] = vals[indices[key]]\n",
    "\n",
    "        # logic\n",
    "        iteration += 1\n",
    "\n",
    "        model = build_model_fn(hp2test)\n",
    "        history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=MAX_EPOCHS,\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE,\n",
    "                                                               restore_best_weights=True)],\n",
    "                      verbose=verbosity)\n",
    "        test_loss, accuracy = model.evaluate(x_val, y_val, verbose=verbosity)\n",
    "        if accuracy > score[-1][0]:\n",
    "            score.append((accuracy, iteration))\n",
    "            best_hps = hp2test.copy()\n",
    "\n",
    "        iterate = False\n",
    "        for key, vals in set_hps.items():\n",
    "            indices[key] += 1\n",
    "            iterate = True\n",
    "            if indices[key] % len(vals) == 0:\n",
    "                indices[key] = 0\n",
    "                iterate = False\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    iterations = 1\n",
    "    for key, vals in set_hps.items():\n",
    "        iterations *= len(vals)\n",
    "    print(\"Expected iterations:\", iterations, \"Done:\", iteration)\n",
    "    return best_hps, score\n",
    "\n",
    "\n",
    "def testing_model(build_model_fn, best_hps, names,\n",
    "                  train_set, val_set, test_set,\n",
    "                  tensorboard_path=None, benchmarks_verbose=0):\n",
    "    dataset_name, class_name, experiment_name, model_name = names\n",
    "    x_train, y_train = train_set\n",
    "    x_val, y_val = val_set\n",
    "    x_test, y_test = test_set\n",
    "\n",
    "    # keras.callbacks.CallbackList([])\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)]\n",
    "    if tensorboard_path is not None:\n",
    "        tensorboard_dir = tensorboard_path + model_name\n",
    "        callbacks.append(keras.callbacks.TensorBoard(tensorboard_dir, profile_batch='500,500'))\n",
    "\n",
    "    print(\"[{}] Running {} benchmarks\".format(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), BENCHMARKS_TRIALS))\n",
    "\n",
    "    test_model = None\n",
    "\n",
    "    required_time = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    tf.random.set_seed(get_seed(names))\n",
    "\n",
    "    for i in range(BENCHMARKS_TRIALS):\n",
    "        initial_time = time()\n",
    "\n",
    "        test_model = build_model_fn(best_hps)\n",
    "        history = test_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=MAX_EPOCHS,\n",
    "                                 # perch√® si usa il validation data?\n",
    "                                 callbacks=callbacks, verbose=benchmarks_verbose)\n",
    "        test_loss, accuracy = test_model.evaluate(x_test, y_test)\n",
    "\n",
    "        required_time.append(time() - initial_time)\n",
    "\n",
    "        train_acc.append(history.history['accuracy'][-1])\n",
    "        val_acc.append(history.history['val_accuracy'][-1])\n",
    "        test_acc.append(accuracy)\n",
    "\n",
    "    stat = Statistic(train_acc, val_acc, test_acc, required_time, dict_hps=best_hps)\n",
    "\n",
    "    return test_model, stat\n",
    "\n",
    "\n",
    "import notify2  # TODO replace notify watch here : https://notify2.readthedocs.io/en/latest/\n",
    "\n",
    "notify2_init = False\n",
    "\n",
    "\n",
    "def send_notification(title, message):\n",
    "    def notify2_init_fun():\n",
    "        global notify2_init\n",
    "        if not notify2_init:\n",
    "            notify2.init(\"Tesi\")\n",
    "\n",
    "    notify2_init_fun()\n",
    "\n",
    "    notice = notify2.Notification(title, message)\n",
    "    notice.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build model functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_ESN(output_classes, _reservoirs, hps) -> ESN:\n",
    "    if output_classes == 2:\n",
    "        output_units = 1\n",
    "        readout_activation = READOUT_ACTIVATION_BINARY\n",
    "        loss = LOSS_FUNCTION_BINARY\n",
    "    else:\n",
    "        output_units = output_classes\n",
    "        readout_activation = READOUT_ACTIVATION\n",
    "        loss = LOSS_FUNCTION\n",
    "\n",
    "    tmp_model = ESN(units=100,\n",
    "                    connectivity=1.,\n",
    "                    spectral_radius=hps['Spectral Radius'],\n",
    "                    input_scaling=hps['Input Scaling'],\n",
    "                    bias_scaling=hps['Bias Scaling'],\n",
    "                    leaky=0.01,\n",
    "                    output_units=output_units,\n",
    "                    readout_activation=readout_activation,\n",
    "                    dtype=tf.float32\n",
    "                    )\n",
    "\n",
    "    alpha = 0.1\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def get_normalization_iiresn(reservoirs, spectral_radius, inter_scaling):\n",
    "    sr = None\n",
    "    if isinstance(spectral_radius, float):\n",
    "        sr = [spectral_radius for _ in range(reservoirs)]\n",
    "    elif isinstance(spectral_radius, list):\n",
    "        if len(spectral_radius) != reservoirs:\n",
    "            raise IndexError\n",
    "        sr = spectral_radius\n",
    "\n",
    "    norm = None\n",
    "    if isinstance(inter_scaling, float):\n",
    "        norm = [[sr[i] if i == j else\n",
    "                 inter_scaling\n",
    "                 for i in range(reservoirs)]\n",
    "                for j in range(reservoirs)]\n",
    "\n",
    "    elif isinstance(inter_scaling, list):\n",
    "        if len(inter_scaling) != reservoirs:\n",
    "            raise IndexError\n",
    "        norm = [[sr[i] if i == j else\n",
    "                 inter_scaling[i]\n",
    "                 for i in range(reservoirs)]\n",
    "                for j in range(reservoirs)]\n",
    "    return norm\n",
    "\n",
    "\n",
    "def build_IIRESN(output_classes, reservoirs, hps) -> IIRESN:\n",
    "    if output_classes == 2:\n",
    "        output_units = 1\n",
    "        readout_activation = READOUT_ACTIVATION_BINARY\n",
    "        loss = LOSS_FUNCTION_BINARY\n",
    "    else:\n",
    "        output_units = output_classes\n",
    "        readout_activation = READOUT_ACTIVATION\n",
    "        loss = LOSS_FUNCTION\n",
    "\n",
    "    try:\n",
    "        spectral_radius = hps['Spectral Radius']\n",
    "    except KeyError:\n",
    "        spectral_radius = [hps['Spectral Radius ' + str(i)] for i in range(reservoirs)]\n",
    "\n",
    "    try:\n",
    "        input_scaling = hps['Input Scaling']\n",
    "    except KeyError:\n",
    "        input_scaling = [hps['Input Scaling ' + str(i)] for i in range(reservoirs)]\n",
    "\n",
    "    try:\n",
    "        inter_scaling = hps['Inter Scaling']\n",
    "    except KeyError:\n",
    "        inter_scaling = [hps['Inter Scaling ' + str(i)] for i in range(reservoirs)]\n",
    "\n",
    "\n",
    "    tmp_model = IIRESN(units=100,\n",
    "                       sub_reservoirs=reservoirs,\n",
    "                       connectivity=[[1. for _ in range(reservoirs)] for _ in range(reservoirs)],\n",
    "                       normalization=get_normalization_iiresn(reservoirs, spectral_radius, inter_scaling),\n",
    "                       use_norm2=False,\n",
    "                       input_scaling=input_scaling,\n",
    "                       bias_scaling=hps['Bias Scaling'],\n",
    "                       leaky=0.01,\n",
    "                       gsr=None,\n",
    "                       vsr=None,\n",
    "                       output_units=output_units,\n",
    "                       readout_activation=readout_activation,\n",
    "                       dtype=tf.float32\n",
    "                       )\n",
    "\n",
    "    alpha = 0.1\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return tmp_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Confiugrations\n",
    "\n",
    "|        | ArticularyWordRecognition | CharacterTrajectories | Epilepsy | JapaneseVowels  | Libras | SpokenArabicDigits |\n",
    "|--------|:-------------------------:|:---------------------:|:--------:|:---------------:|:------:|:------------------:|\n",
    "| Input  |             9             |           3           |    3     |       12        |   2    |         13         |\n",
    "| Output |            25             |          20           |    4     |        9        |   15   |         10         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "\n",
    "def get_name(fn):\n",
    "    return fn.__annotations__['return'].__name__\n",
    "\n",
    "\n",
    "config = {\n",
    "    'Datasets'                             : [\n",
    "        \"Libras\",\n",
    "        #\"Epilepsy\",\n",
    "        #\"CharacterTrajectories\",\n",
    "        #\"ArticularyWordRecognition\",\n",
    "        #\"JapaneseVowels\"\n",
    "        #\"SpokenArabicDigits\",\n",
    "    ],\n",
    "    'Classes'                              : [\n",
    "        'Reference',\n",
    "        'Single SR Single Input Single Inter',\n",
    "        'Multiple SR Single Input Single Inter',\n",
    "        'Single SR Multiple Input Single Inter',\n",
    "        'Single SR Single Input Multiple Inter',\n",
    "    ],\n",
    "    'Reference'                            : {\n",
    "        'Models'     : [\n",
    "            build_ESN\n",
    "        ],\n",
    "        'Experiments': {\n",
    "            'Units 100': hyperparameters,\n",
    "        }\n",
    "    },\n",
    "    'Single SR Single Input Single Inter'  : {\n",
    "        'Models'     : [\n",
    "            build_IIRESN,\n",
    "        ],\n",
    "        'Experiments': {\n",
    "            'Units 100': hyperparameters,\n",
    "        }\n",
    "    },\n",
    "    'Multiple SR Single Input Single Inter': {\n",
    "        'Models'     : [\n",
    "            build_IIRESN,\n",
    "        ],\n",
    "        'Experiments': {\n",
    "            'Units 100': hyperparameters,\n",
    "        }\n",
    "    },\n",
    "    'Single SR Multiple Input Single Inter': {\n",
    "        'Models'     : [\n",
    "            build_IIRESN,\n",
    "        ],\n",
    "        'Experiments': {\n",
    "            'Units 100': hyperparameters,\n",
    "        },\n",
    "    },\n",
    "    'Single SR Single Input Multiple Inter': {\n",
    "        'Models'     : [\n",
    "            build_IIRESN,\n",
    "        ],\n",
    "        'Experiments': {\n",
    "            'Units 100': hyperparameters,\n",
    "        },\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/05/2022 20:56:06] M.S. of                    Libras                             Reference  Units 100        ESN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected iterations: 45 Done: 45\n",
      "[08/05/2022 20:56:28] M.S. run time 0:00:22.512946\n",
      "[08/05/2022 20:56:28] Running 1 benchmarks\n",
      "6/6 [==============================] - 0s 619us/step - loss: 2.7500 - accuracy: 0.0889\n",
      "[08/05/2022 20:56:31] M.S. of                    Libras   Single SR Single Input Single Inter  Units 100     IIRESN\n",
      "Expected iterations: 180 Done: 180\n",
      "[08/05/2022 20:57:59] M.S. run time 0:01:28.246915\n",
      "[08/05/2022 20:57:59] Running 1 benchmarks\n",
      "6/6 [==============================] - 0s 765us/step - loss: 2.5879 - accuracy: 0.1500\n",
      "[08/05/2022 20:58:02] M.S. of                    Libras Multiple SR Single Input Single Inter  Units 100     IIRESN\n",
      "Expected iterations: 900 Done: 900\n",
      "[08/05/2022 21:05:27] M.S. run time 0:07:25.611164\n",
      "[08/05/2022 21:05:27] Running 1 benchmarks\n",
      "6/6 [==============================] - 0s 510us/step - loss: 2.5995 - accuracy: 0.1611\n",
      "[08/05/2022 21:05:30] M.S. of                    Libras Single SR Multiple Input Single Inter  Units 100     IIRESN\n",
      "Expected iterations: 540 Done: 540\n",
      "[08/05/2022 21:10:00] M.S. run time 0:04:30.350013\n",
      "[08/05/2022 21:10:00] Running 1 benchmarks\n",
      "6/6 [==============================] - 0s 528us/step - loss: 2.5675 - accuracy: 0.1833\n",
      "[08/05/2022 21:10:02] M.S. of                    Libras Single SR Single Input Multiple Inter  Units 100     IIRESN\n",
      "Expected iterations: 720 Done: 720\n",
      "[08/05/2022 21:16:06] M.S. run time 0:06:03.399593\n",
      "[08/05/2022 21:16:06] Running 1 benchmarks\n",
      "6/6 [==============================] - 0s 562us/step - loss: 2.7442 - accuracy: 0.0889\n",
      "Requested time: 0:20:02.275827\n"
     ]
    }
   ],
   "source": [
    "def get_date():\n",
    "    return datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "from plotting import plot_model\n",
    "\n",
    "datasets = config.get('Datasets')\n",
    "classes = config.get('Classes')\n",
    "\n",
    "run_time = time()\n",
    "for dataset_name in datasets:\n",
    "    train_path = os.path.join(DATA_ROOT, dataset_name, dataset_name + '_TRAIN.ts')\n",
    "    test_path = os.path.join(DATA_ROOT, dataset_name, dataset_name + '_TEST.ts')\n",
    "\n",
    "    x_train_all, y_train_all = load_sktime_dataset(train_path)\n",
    "    x_test, y_test = load_sktime_dataset(test_path)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                      test_size=0.33, random_state=42, stratify=y_train_all)\n",
    "\n",
    "    train_set = (x_train.astype(np.float32), y_train)\n",
    "    val_set = (x_val.astype(np.float32), y_val)\n",
    "    test_set = (x_test.astype(np.float32), y_test)\n",
    "\n",
    "    input_dim = x_train.shape[-1]\n",
    "    output_units = len(np.unique(y_test))  # Dataset must have one of each features\n",
    "\n",
    "    for class_name in classes:\n",
    "        for experiment_name, hps in config.get(class_name).get(\"Experiments\").items():\n",
    "            for model_fn in config.get(class_name).get(\"Models\"):\n",
    "                model_name = get_name(model_fn)\n",
    "                print(\"[{}] M.S. of {: >25} {: >37} {: >10} {: >10}\".format(get_date(),\n",
    "                                                                            dataset_name, class_name, experiment_name,\n",
    "                                                                            model_name))\n",
    "                already_tested = benchmarks.is_benchmarked(dataset_name, class_name, experiment_name, model_name)\n",
    "                if already_tested and SKIP:\n",
    "                    print(\"[                   ] Skip Already tested!\")\n",
    "                    continue\n",
    "                start_model = time()\n",
    "                build_fn = partial(model_fn, output_units, input_dim)\n",
    "                names = (dataset_name, class_name, experiment_name, model_name)\n",
    "\n",
    "                best_hp, score = model_selection(build_fn, hyperparameters, input_dim, names, train_set, val_set)\n",
    "\n",
    "                duration = time() - start_model\n",
    "                string_out = \"[\" + get_date() + \"] M.S. run time \" + str(timedelta(seconds=duration))\n",
    "                print(string_out)\n",
    "\n",
    "                if BENCHMARKS_TRIALS > 0:\n",
    "                    model, stat = testing_model(build_fn, best_hp, names, train_set, val_set, test_set)\n",
    "                    stat.add_score(score)\n",
    "                    benchmarks.add(dataset_name, class_name, experiment_name, model_name, stat)\n",
    "                    plot_model(model, names, path=WEIGHTS_ROOT, show=False)\n",
    "\n",
    "                benchmarks.save()\n",
    "\n",
    "duration = time() - run_time\n",
    "string_out = \"Requested time: \" + str(timedelta(seconds=duration))\n",
    "print(string_out)\n",
    "send_notification(\"All Done\", string_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%time\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}