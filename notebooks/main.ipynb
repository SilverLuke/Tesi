{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Data dir: /dati/luca/Uni-Luca/Tesi/tesi/datasets\n",
      "      Tuner dir: /dati/luca/Uni-Luca/Tesi/tesi/models\n",
      "Tensorboard dir: /tmp/tensorboard\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from functools import *\n",
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd() + os.sep + os.pardir)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from lib.time_series_datasets import *\n",
    "from lib.models import *\n",
    "from lib.benchmarks import *\n",
    "import notify2  # ToDo replace notify watch here : https://notify2.readthedocs.io/en/latest/\n",
    "\n",
    "DATA_ROOT = os.path.join(PROJECT_ROOT, \"datasets\")\n",
    "TUNER_ROOT = os.path.join(PROJECT_ROOT, \"models\")\n",
    "BENCHMARKS_ROOT = os.path.join(PROJECT_ROOT, \"plots\", \"benchmarks\")\n",
    "WEIGHTS_ROOT = os.path.join(PROJECT_ROOT, \"plots\", \"weights\")\n",
    "TB_ROOT = os.path.join(os.path.abspath(os.sep), \"tmp\", \"tensorboard\")\n",
    "\n",
    "BENCHMARKS_DIR = \"benchmarks\"\n",
    "WEIGHTS_DIR = \"weights\"\n",
    "\n",
    "print(\"       Data dir:\", DATA_ROOT)\n",
    "print(\"      Tuner dir:\", TUNER_ROOT)\n",
    "print(\"Tensorboard dir:\", TB_ROOT)\n",
    "\n",
    "TUNER = \"BayesianOptimization\"  # \"Hyperband\" or \"BayesianOptimization\"\n",
    "SKIP = True  # Re benchmark a model if already tested ?\n",
    "\n",
    "MAX_UNITS = 400\n",
    "MAX_EPOCHS = 200\n",
    "GUESSES = 10\n",
    "PATIENCE = 10\n",
    "\n",
    "MAX_TRIALS = 100  # BayesianOptimization\n",
    "\n",
    "#set the following values based on the specific dataset\n",
    "OUTPUT_ACTIVATION = tf.keras.activations.softmax  # https://www.tensorflow.org/api_docs/python/tf/keras/activations  'softmax'\n",
    "LOSS_FUNCTION = tf.keras.losses.SparseCategoricalCrossentropy()  # https://www.tensorflow.org/api_docs/python/tf/keras/losses  'sparse_categorical_crossentropy'\n",
    "\n",
    "if not os.path.exists(TUNER_ROOT):\n",
    "    os.makedirs(TUNER_ROOT)\n",
    "if not os.path.exists(TB_ROOT):\n",
    "    os.makedirs(TB_ROOT)\n",
    "\n",
    "benchmarks = BenchmarksDB(load_path=os.path.join(BENCHMARKS_ROOT, \"benchmarks.json\"), plot_path=WEIGHTS_ROOT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "|        | ArticularyWordRecognition | CharacterTrajectories | Libras | SpokenArabicDigits |\n",
    "|--------|:-------------------------:|:---------------------:|:------:|:------------------:|\n",
    "| Input  |             9             |           3           |   2    |         13         |\n",
    "| Output |            25             |          20           |   15   |         10         |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from keras_tuner import Hyperband, BayesianOptimization\n",
    "\n",
    "\n",
    "def tune_and_test(build_model_fn, names,\n",
    "                  train_set, val_set, test_set,\n",
    "                  tuner_path, tensorboard_path=None,\n",
    "                  benchmarks_verbose=0):\n",
    "    dataset_name, class_name, experiment_name, model_name = names\n",
    "    x_train, y_train = train_set\n",
    "    x_val, y_val = val_set\n",
    "    x_test, y_test = test_set\n",
    "    if TUNER == \"Hyperband\":\n",
    "        working_dir = os.path.join(tuner_path, \"Hyperband\", dataset_name, class_name)\n",
    "        if not os.path.exists(working_dir):\n",
    "            os.makedirs(working_dir)\n",
    "\n",
    "        tuner = Hyperband(\n",
    "            build_model_fn,\n",
    "            objective='val_accuracy',\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            hyperband_iterations=1.,\n",
    "            seed=42,\n",
    "\n",
    "            directory=working_dir,\n",
    "            project_name=experiment_name + ' ' + model_name,\n",
    "            overwrite=False,\n",
    "        )\n",
    "    elif TUNER == \"BayesianOptimization\":\n",
    "        working_dir = os.path.join(tuner_path, \"BayesianOptimization\", dataset_name, class_name)\n",
    "        if not os.path.exists(working_dir):\n",
    "            os.makedirs(working_dir)\n",
    "\n",
    "        tuner = BayesianOptimization(\n",
    "            build_model_fn,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=MAX_TRIALS,\n",
    "            #num_initial_points=2,\n",
    "            seed=42,\n",
    "\n",
    "            directory=working_dir,\n",
    "            project_name=experiment_name + ' ' + model_name,\n",
    "            overwrite=False,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Tuner var contains a bad value -> {}\".format(TUNER))\n",
    "\n",
    "    tuner.search(x_train, y_train, epochs=MAX_EPOCHS, validation_data=(x_val, y_val),\n",
    "                 callbacks=[\n",
    "                     keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "                 ])\n",
    "\n",
    "    # choose the best hyperparameters  # tf.keras.callbacks.CallbackList([])\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)]\n",
    "    if tensorboard_path is not None:\n",
    "        tensorboard_dir = tensorboard_path + model_name\n",
    "        callbacks.append(keras.callbacks.TensorBoard(tensorboard_dir, profile_batch='500,500'))\n",
    "\n",
    "    print(\"Start {} benchmarks for {} | {} | {} | {}:\".format(GUESSES, dataset_name, class_name, experiment_name,\n",
    "                                                              model_name))\n",
    "    best_model_hp = tuner.get_best_hyperparameters()[0]\n",
    "    test_model = None\n",
    "\n",
    "    metrics_ts = []\n",
    "    loss_ts = []\n",
    "    required_time = []\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    for i in range(GUESSES):\n",
    "        initial_time = time()\n",
    "\n",
    "        test_model = tuner.hypermodel.build(best_model_hp)\n",
    "        test_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=MAX_EPOCHS,\n",
    "                       callbacks=callbacks, verbose=benchmarks_verbose)\n",
    "        loss, metrics = test_model.evaluate(x_test, y_test)\n",
    "\n",
    "        required_time.append(time() - initial_time)\n",
    "        metrics_ts.append(metrics)\n",
    "        loss_ts.append(loss)\n",
    "\n",
    "    stat = Statistic(best_model_hp, metrics_ts, loss_ts, required_time)\n",
    "\n",
    "    return test_model, stat\n",
    "\n",
    "\n",
    "notify2_init = False\n",
    "\n",
    "\n",
    "def send_notification(title, message):\n",
    "    def notify2_init_fun():\n",
    "        global notify2_init\n",
    "        if not notify2_init:\n",
    "            notify2.init(\"Tesi\")\n",
    "\n",
    "    notify2_init_fun()\n",
    "\n",
    "    notice = notify2.Notification(title, message)\n",
    "    notice.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# This cell is a little nightmare\n",
    "\n",
    "class HP:\n",
    "    FREE = 0\n",
    "    FIXED = 1\n",
    "    RESTRICTED = 2\n",
    "\n",
    "    def __init__(self, hp_type, value=None):\n",
    "        self.value = value\n",
    "        self.type = hp_type\n",
    "\n",
    "    @classmethod\n",
    "    def free(cls):\n",
    "        return cls(HP.FREE)\n",
    "\n",
    "    @classmethod\n",
    "    def fixed(cls, value):\n",
    "        return cls(HP.FIXED, value)\n",
    "\n",
    "    @classmethod\n",
    "    def restricted(cls, value=None):\n",
    "        return cls(HP.RESTRICTED, value)\n",
    "\n",
    "\n",
    "def get_int(tuner, name, hp, min_value, max_value, step=1, sampling=None, pn=None, pv=None):\n",
    "    if hp.type == HP.FREE or hp.type == HP.RESTRICTED:\n",
    "        tmp = tuner.Int(name, min_value=min_value, max_value=max_value, step=step, sampling=sampling, parent_name=pn,\n",
    "                        parent_values=pv)\n",
    "    elif hp.type == HP.FIXED:\n",
    "        tmp = tuner.Fixed(name, hp.value)\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_float(tuner, name, hp, min_value, max_value, step=None, sampling=None, pn=None, pv=None):\n",
    "    if hp.type == HP.FREE or hp.type == HP.RESTRICTED:\n",
    "        tmp = tuner.Float(name, min_value=min_value, max_value=max_value, step=step, sampling=sampling, parent_name=pn,\n",
    "                          parent_values=pv)\n",
    "    elif hp.type == HP.FIXED:\n",
    "        tmp = tuner.Fixed(name, hp.value)\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_bool(tuner, name, hp):\n",
    "    if hp.type == HP.FREE or hp.type == HP.RESTRICTED:\n",
    "        tmp = tuner.Boolean(name)\n",
    "    elif hp.type == HP.FIXED:\n",
    "        tmp = tuner.Fixed(name, hp.value)\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_float_vec(tuner, name, hp, length, min_value, max_value, step=None, sampling=None, pn=None, pv=None):\n",
    "    if hp.type == HP.FREE:\n",
    "        tmp = [tuner.Float(name + ' ' + str(i), min_value=min_value, max_value=max_value, sampling=sampling,\n",
    "                           parent_name=pn, parent_values=pv)\n",
    "               for i in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        tmp = [tuner.Fixed(name + ' ' + str(i), hp[i]) for i in range(length)]\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        tmp2 = tuner.Float(name + ' 0', min_value=min_value, max_value=max_value, sampling=sampling, parent_name=pn,\n",
    "                           parent_values=pv)\n",
    "        tmp = [tmp2 for _ in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_connectivity(tuner, hp, length):  # It is a squared matrix\n",
    "    if hp.type == HP.FREE:\n",
    "        conn_matrix = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) if i == j else\n",
    "                        tuner.Float('connectivity ' + str(i) + '->' + str(j), min_value=0., max_value=1.)\n",
    "                        for i in range(length)]\n",
    "                       for j in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        diagonal, off_diagonal = hp.value\n",
    "        off_diagonal = tuner.Fixed('connectivity X->Y', off_diagonal)\n",
    "        conn_matrix = [[tuner.Fixed('connectivity ' + str(i), diagonal) if i == j else\n",
    "                        off_diagonal\n",
    "                        for i in range(length)]\n",
    "                       for j in range(length)]\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        if hp.value is None:\n",
    "            connectivity = [tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) for i in range(length)]\n",
    "        else:\n",
    "            tmp = tuner.Fixed('connectivity', hp.value)\n",
    "            connectivity = [ tmp for _ in range(length)]\n",
    "        intra_connectivity = tuner.Float('connectivity X->Y', min_value=0., max_value=1.)\n",
    "        conn_matrix = [[connectivity[i] if i == j else intra_connectivity for i in range(length)] for j in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return conn_matrix\n",
    "\n",
    "\n",
    "def get_spectral_radius(tuner, hp, length):\n",
    "    max_value = 2.0\n",
    "    if hp.type == HP.FREE:\n",
    "        off_diagonal = tuner.Float('spectral radius X->Y', min_value=0.0, max_value=max_value, step=0.1)\n",
    "        sr_matrix = \\\n",
    "            [[tuner.Float('spectral radius ' + str(i), min_value=0.0, max_value=max_value, step=0.1) if i == j else\n",
    "             off_diagonal\n",
    "             for i in range(length)]\n",
    "            for j in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        diagonal, off_diagonal = hp.value\n",
    "        sr_matrix = [[tuner.Fixed('spectral radius ' + str(i), diagonal) if i == j else\n",
    "                      tuner.Fixed('spectral radius ' + str(i) + '->' + str(j), off_diagonal)\n",
    "                      for i in range(length)]\n",
    "                     for j in range(length)]\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        connectivity = tuner.Float('spectral radius', min_value=0.0, max_value=max_value, step=0.1)\n",
    "        intra_connectivity = tuner.Float('spectral radius X->Y', min_value=0.0, max_value=max_value, step=0.1)\n",
    "        sr_matrix = [[connectivity if i == j else intra_connectivity for i in range(length)] for j in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return sr_matrix\n",
    "\n",
    "\n",
    "def get_gsr(tuner, gsr):\n",
    "    global_sr = get_bool(tuner, 'use G.S.R', gsr)\n",
    "    if global_sr:\n",
    "        global_sr = tuner.Float('G.S.R', min_value=0.01, max_value=2., sampling='log', parent_name='use G.S.R', parent_values=True)\n",
    "    else:\n",
    "        global_sr = None #  tuner.Fixed('G.S.R', False, parent_name='use G.S.R', parent_values=False)\n",
    "\n",
    "    return global_sr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def build_ESN1(output, _reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, _gsr, connectivity, input_scaling, bias_scaling, leaky, learning_rate,\n",
    "               # Defined by experiment\n",
    "               tuner) -> ESN1:\n",
    "    tmp_model = ESN1(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     connectivity=get_float(tuner, 'connectivity 0', connectivity, 0.001, 1.),\n",
    "                     spectral_radius=get_float(tuner, 'spectral radius', spectral_radius, min_value=0.001, max_value=2.,\n",
    "                                               sampling='log'),\n",
    "                     output_units=output,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=get_float(tuner, 'input scaling', input_scaling, 0.1, 1.5, step=0.1),\n",
    "                     bias_scaling=get_float(tuner, 'bias scaling', bias_scaling, min_value=0.1, max_value=1.5,\n",
    "                                            step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.1, max_value=1, step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN2(output, reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, gsr, connectivity, input_scaling, bias_scaling, leaky, learning_rate,\n",
    "               # Defined by experiment\n",
    "               tuner) -> ESN2:\n",
    "    tmp_model = ESN2(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     sub_reservoirs=reservoirs,\n",
    "                     connectivity=get_float_vec(tuner, 'connectivity', connectivity, reservoirs, min_value=0.0,\n",
    "                                                max_value=1.),\n",
    "                     spectral_radius=get_float_vec(tuner, 'spectral radius', spectral_radius, reservoirs,\n",
    "                                                   min_value=0.01, max_value=2., sampling='log'),\n",
    "                     gsr=get_gsr(tuner, gsr),\n",
    "                     output_units=output,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=get_float_vec(tuner, 'input scaling', input_scaling, reservoirs, min_value=0.1,\n",
    "                                                 max_value=1.5, step=0.1),\n",
    "                     bias_scaling=get_float_vec(tuner, 'bias scaling', bias_scaling, reservoirs, min_value=0.1,\n",
    "                                                max_value=1.5, step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.1, max_value=1, step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN3(output, reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, gsr, connectivity, input_scaling, bias_scaling, leaky, learning_rate,\n",
    "               # Defined by experiment\n",
    "               tuner) -> ESN3:\n",
    "    tmp_model = ESN3(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     sub_reservoirs=reservoirs,\n",
    "                     connectivity=get_connectivity(tuner, connectivity, reservoirs),\n",
    "                     spectral_radius=get_spectral_radius(tuner, spectral_radius, reservoirs),\n",
    "                     gsr=get_gsr(tuner, gsr),\n",
    "                     output_units=output,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=get_float_vec(tuner, 'input scaling', input_scaling, reservoirs, min_value=0.1,\n",
    "                                                 max_value=1.5, step=0.1),\n",
    "                     bias_scaling=get_float_vec(tuner, 'bias scaling', bias_scaling, reservoirs, min_value=0.1,\n",
    "                                                max_value=1.5, step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.1, max_value=1, step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN4(output, reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, gsr, connectivity, input_scaling, bias_scaling, leaky, learning_rate,\n",
    "               # Defined by experiment\n",
    "               tuner) -> ESN4:\n",
    "    partitions = [tuner.Float('partition ' + str(i), min_value=0., max_value=1.0) for i in range(reservoirs)]\n",
    "    total = sum(partitions)\n",
    "    # Normalize the partition vector now sum(partitions) == 1.\n",
    "    partitions = list(map(lambda _x: 0 if total == 0 else _x / total, partitions))\n",
    "\n",
    "    tmp_model = ESN4(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     sub_reservoirs=reservoirs,\n",
    "                     connectivity=get_connectivity(tuner, connectivity, reservoirs),\n",
    "                     partitions=partitions,\n",
    "                     spectral_radius=get_spectral_radius(tuner, spectral_radius, reservoirs),\n",
    "                     gsr=get_gsr(tuner, gsr),\n",
    "                     output_units=output,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=get_float_vec(tuner, 'input scaling', input_scaling, reservoirs, min_value=0.1,\n",
    "                                                 max_value=1.5, step=0.1),\n",
    "                     bias_scaling=get_float_vec(tuner, 'bias scaling', bias_scaling, reservoirs, min_value=0.1,\n",
    "                                                max_value=1.5, step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.1, max_value=1, step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments configs:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "config = {\n",
    "    'Datasets': [\"ArticularyWordRecognition\"],# \"CharacterTrajectories\", \"Libras\", \"SpokenArabicDigits\", \"Epilepsy\", \"JapaneseVowels\"],\n",
    "    'Classes': [\"Best Models\"],\n",
    "    'Models': [build_ESN1, build_ESN2, build_ESN3, build_ESN4],\n",
    "    #                Units         | Spectral radius| G.S.R         | Connectivity     | Input scaling  | Bias scaling   | leaky    | learning rate\n",
    "    #                F             | F-R            | F             | F - R            | F-R            | F-R            | F        | F\n",
    "    'Best Models': {\n",
    "        'Best':      (HP.free(),     HP.free(),       HP.free(),      HP.restricted(),   HP.free(),       HP.free(),       HP.free(), HP.free())\n",
    "    },\n",
    "    'N SR': {  # Modello con N sub res ora ha 7 + N ( N diag sr + 1 off diag st, 1 g.s.r., 1 offdiag conn, 1 input, 1 bias, 1 leaky, 1 learning)\n",
    "         'Units 50': (HP.fixed(50),  HP.free(),       HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "         'Units 75': (HP.fixed(75),  HP.free(),       HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 112': (HP.fixed(122), HP.free(),       HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 168': (HP.fixed(168), HP.free(),       HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 253': (HP.fixed(253), HP.free(),       HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 379': (HP.fixed(379), HP.free(),       HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    },\n",
    "    'Single SR': {\n",
    "         'Units 50': (HP.fixed(50),  HP.restricted(), HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    #     'Units 75': (HP.fixed(75),  HP.restricted(), HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    #    'Units 100': (HP.fixed(100), HP.restricted(), HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    #    'Units 150': (HP.fixed(150), HP.restricted(), HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    #    'Units 200': (HP.fixed(200), HP.restricted(), HP.free(),      HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/BayesianOptimization/ArticularyWordRecognition/Best Models/Best ESN3/oracle.json\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |274               |?                 \n",
      "connectivity 0    |0.038552          |?                 \n",
      "connectivity 1    |0.40854           |?                 \n",
      "connectivity 2    |0.27188           |?                 \n",
      "connectivity 3    |0.88827           |?                 \n",
      "connectivity 4    |0.35185           |?                 \n",
      "connectivity 5    |0.54816           |?                 \n",
      "connectivity 6    |0.066884          |?                 \n",
      "connectivity 7    |0.49754           |?                 \n",
      "connectivity 8    |0.24352           |?                 \n",
      "connectivity X->Y |0.97835           |?                 \n",
      "spectral radius...|1.2               |?                 \n",
      "spectral radius 0 |1.8               |?                 \n",
      "spectral radius 1 |0.2               |?                 \n",
      "spectral radius 2 |1.9               |?                 \n",
      "spectral radius 3 |0.1               |?                 \n",
      "spectral radius 4 |1.2               |?                 \n",
      "spectral radius 5 |0.4               |?                 \n",
      "spectral radius 6 |0.6               |?                 \n",
      "spectral radius 7 |1                 |?                 \n",
      "spectral radius 8 |1.9               |?                 \n",
      "use G.S.R         |False             |?                 \n",
      "input scaling 0   |0.76662           |?                 \n",
      "input scaling 1   |0.68064           |?                 \n",
      "input scaling 2   |0.19913           |?                 \n",
      "input scaling 3   |0.20471           |?                 \n",
      "input scaling 4   |1.1383            |?                 \n",
      "input scaling 5   |1.0579            |?                 \n",
      "input scaling 6   |1.3737            |?                 \n",
      "input scaling 7   |0.55325           |?                 \n",
      "input scaling 8   |0.2028            |?                 \n",
      "bias scaling 0    |0.49174           |?                 \n",
      "bias scaling 1    |1.3036            |?                 \n",
      "bias scaling 2    |0.73118           |?                 \n",
      "bias scaling 3    |0.61878           |?                 \n",
      "bias scaling 4    |1.2188            |?                 \n",
      "bias scaling 5    |1.2403            |?                 \n",
      "bias scaling 6    |0.30347           |?                 \n",
      "bias scaling 7    |0.48009           |?                 \n",
      "bias scaling 8    |0.80832           |?                 \n",
      "leaky             |0.2               |?                 \n",
      "learning rate     |0.00096522        |?                 \n",
      "\n",
      "<class 'float'> 1.8\n",
      "<class 'float'> 1.2000000000000002\n",
      "<class 'float'> 1.2000000000000002\n",
      "<class 'float'> 1.2000000000000002\n",
      "<class 'float'> 1.2000000000000002\n",
      "<class 'float'> 1.8\n",
      "<class 'float'> 1.2000000000000002\n",
      "<class 'float'> 1.2000000000000002\n",
      "<class 'float'> 1.2000000000000002\n",
      "<class 'float'> 1.2000000000000002\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInput matrix must be square. [Op:Eig]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(184, 144, 9), dtype=float64)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     30\u001B[0m build_fn \u001B[38;5;241m=\u001B[39m partial(model_fn, output_units, features, \u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m     31\u001B[0m names \u001B[38;5;241m=\u001B[39m (dataset, class_name, experiment, model_name)\n\u001B[0;32m---> 32\u001B[0m model, stat \u001B[38;5;241m=\u001B[39m \u001B[43mtune_and_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuild_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mtuner_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTUNER_ROOT\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m benchmarks\u001B[38;5;241m.\u001B[39madd(dataset, class_name, experiment, model_name, stat)\n\u001B[1;32m     36\u001B[0m model\u001B[38;5;241m.\u001B[39mplot(names, path\u001B[38;5;241m=\u001B[39mWEIGHTS_ROOT, show\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mtune_and_test\u001B[0;34m(build_model_fn, names, train_set, val_set, test_set, tuner_path, tensorboard_path, benchmarks_verbose)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTuner var contains a bad value -> \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(TUNER))\n\u001B[0;32m---> 47\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMAX_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m             \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPATIENCE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m             \u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# choose the best hyperparameters  # tf.keras.callbacks.CallbackList([])\u001B[39;00m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39mPATIENCE, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)]\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[0;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[0;32m--> 179\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001B[39;00m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m results \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:304\u001B[0m, in \u001B[0;36mTuner.run_trial\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    302\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mappend(model_checkpoint)\n\u001B[1;32m    303\u001B[0m copied_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m callbacks\n\u001B[0;32m--> 304\u001B[0m obj_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_and_fit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcopied_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;66;03m# objective left unspecified,\u001B[39;00m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;66;03m# and objective value is not a single float.\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj_value, (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m))\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mobjective\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault_objective\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    311\u001B[0m ):\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:234\u001B[0m, in \u001B[0;36mTuner._build_and_fit_model\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    232\u001B[0m hp \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39mhyperparameters\n\u001B[1;32m    233\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_build(hp)\n\u001B[0;32m--> 234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001B[0m, in \u001B[0;36mHyperModel.fit\u001B[0;34m(self, hp, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, hp, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;124;03m\"\"\"Train the model.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \n\u001B[1;32m    116\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m        If return a float, it should be the `objective` value.\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/models.py:33\u001B[0m, in \u001B[0;36mESNInterface.fit\u001B[0;34m(self, x, y, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# applies the reservoirs to all the input sequences in the training set\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m     x_train_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreservoir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;66;03m# does the same for the validation set\u001B[39;00m\n\u001B[1;32m     36\u001B[0m     x_val, y_val \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation_data\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/esn.py:108\u001B[0m, in \u001B[0;36mReservoir.build\u001B[0;34m(self, inputs_shape)\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     96\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not infer input size from inputs.get_shape()[-1]. Shape received is \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     97\u001B[0m         \u001B[38;5;241m%\u001B[39m inputs_shape\n\u001B[1;32m     98\u001B[0m     )\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_weight(\n\u001B[1;32m    101\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkernel\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    102\u001B[0m     shape\u001B[38;5;241m=\u001B[39m[input_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munits],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    105\u001B[0m     dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[1;32m    106\u001B[0m )\n\u001B[0;32m--> 108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurrent_kernel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_weight\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrecurrent_kernel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munits\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecurrent_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    114\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_bias:\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_weight(\n\u001B[1;32m    118\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbias\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    119\u001B[0m         shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munits],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m         dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[1;32m    123\u001B[0m     )\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/initializers.py:215\u001B[0m, in \u001B[0;36mRecurrentKernel.__call__\u001B[0;34m(self, shape, dtype, **kwargs)\u001B[0m\n\u001B[1;32m    213\u001B[0m         connectivity \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrc[i][j]\n\u001B[1;32m    214\u001B[0m         spectral_radius \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspectral_radius[i][j]\n\u001B[0;32m--> 215\u001B[0m         recurrent_kernels[i][j] \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspectral_radius\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnectivity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m matrix \u001B[38;5;241m=\u001B[39m join_matrices(recurrent_kernels)\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgsr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# Normalize the entire matrix\u001B[39;00m\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/initializers.py:56\u001B[0m, in \u001B[0;36mgenerate_matrix\u001B[0;34m(shape, initializer, spectral_radius, connectivity, dtype)\u001B[0m\n\u001B[1;32m     54\u001B[0m     matrix \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mmultiply(matrix, connectivity_mask)\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(spectral_radius), spectral_radius)\n\u001B[0;32m---> 56\u001B[0m     scaling \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mdivide_no_nan(spectral_radius, \u001B[43mget_spectral_radius\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmatrix\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     57\u001B[0m     matrix \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmultiply(matrix, scaling)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m matrix\n",
      "File \u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/initializers.py:23\u001B[0m, in \u001B[0;36mget_spectral_radius\u001B[0;34m(tensor)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_spectral_radius\u001B[39m(tensor):\n\u001B[0;32m---> 23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcast(tf\u001B[38;5;241m.\u001B[39mreduce_max(tf\u001B[38;5;241m.\u001B[39mabs(\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])), tf\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInput matrix must be square. [Op:Eig]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(184, 144, 9), dtype=float64)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "datasets = config.get('Datasets')\n",
    "classes = config.get('Classes')\n",
    "models_fn = config.get('Models')\n",
    "#benchmarks = BenchmarksDB()\n",
    "\n",
    "start_learning = time()\n",
    "for dataset in datasets:\n",
    "    train_path = os.path.join(DATA_ROOT, dataset, dataset + '_TRAIN.ts')\n",
    "    test_path = os.path.join(DATA_ROOT, dataset, dataset + '_TEST.ts')\n",
    "\n",
    "    x_train_all, y_train_all = load_sktime_dataset(train_path)\n",
    "    x_test, y_test = load_sktime_dataset(test_path)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                      test_size=0.33, random_state=42, stratify=y_train_all)\n",
    "\n",
    "    train_set = (x_train.astype(np.float64), y_train.astype(np.float64))  # Todo is this cast necessary?\n",
    "    val_set = (x_val.astype(np.float64), y_val.astype(np.float64))\n",
    "    test_set = (x_test.astype(np.float64), y_test.astype(np.float64))\n",
    "\n",
    "    features = x_train.shape[-1]\n",
    "    output_units = len(np.unique(y_test))  # Dataset must have one of each features\n",
    "\n",
    "    for class_name in classes:\n",
    "        for experiment, params in config.get(class_name).items():\n",
    "            for model_fn in models_fn:\n",
    "                model_name = model_fn.__annotations__['return'].__name__\n",
    "                if benchmarks.is_benchmarked(dataset, class_name, experiment, model_name) and True:\n",
    "                    continue\n",
    "                build_fn = partial(model_fn, output_units, features, *params)\n",
    "                names = (dataset, class_name, experiment, model_name)\n",
    "                model, stat = tune_and_test(build_fn, names,\n",
    "                                            train_set, val_set, test_set,\n",
    "                                            tuner_path=TUNER_ROOT)\n",
    "                benchmarks.add(dataset, class_name, experiment, model_name, stat)\n",
    "                model.plot(names, path=WEIGHTS_ROOT, show=False)\n",
    "                #send_notification(experiment + \" \" + model_name, dataset + \" Accuracy \" + stat.get_accuracy_str())\n",
    "\n",
    "print(\"Total learning time:\" + str(time() - start_learning))\n",
    "send_notification(\"All Done\", \"Requested time:\" + str(time() - start_learning))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for d, c, e, m, stat in benchmarks:\n",
    "    #  ret += \"Hyperparameters:\\n\"\n",
    "    print(d, c, e, m)\n",
    "    print(stat.get_accuracy_str())\n",
    "    for key, val in stat.hyperparameters.values.items():\n",
    "        print(\"{}: {}\".format(key, val))\n",
    "    print(\"######################\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}