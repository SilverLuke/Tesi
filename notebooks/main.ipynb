{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Data dir: /dati/luca/Uni-Luca/Tesi/progetto/datasets\n",
      "      Tuner dir: /dati/luca/Uni-Luca/Tesi/progetto/models\n",
      "Tensorboard dir: /tmp/tensorboard\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from functools import *\n",
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd() + os.sep + os.pardir)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from lib.time_series_datasets import *\n",
    "from lib.models import *\n",
    "from lib.benchmarks import *\n",
    "import notify2  # TODO replace notify watch here : https://notify2.readthedocs.io/en/latest/\n",
    "from tensorflow import keras\n",
    "\n",
    "DATA_ROOT = os.path.join(PROJECT_ROOT, \"datasets\")\n",
    "TUNER_ROOT = os.path.join(PROJECT_ROOT, \"models\")\n",
    "BENCHMARKS_ROOT = os.path.join(PROJECT_ROOT, \"plots\", \"benchmarks\")\n",
    "WEIGHTS_ROOT = os.path.join(PROJECT_ROOT, \"plots\", \"weights\")\n",
    "TB_ROOT = os.path.join(os.path.abspath(os.sep), \"tmp\", \"tensorboard\")\n",
    "\n",
    "BENCHMARKS_DIR = \"benchmarks\"\n",
    "WEIGHTS_DIR = \"weights\"\n",
    "\n",
    "print(\"       Data dir:\", DATA_ROOT)\n",
    "print(\"      Tuner dir:\", TUNER_ROOT)\n",
    "print(\"Tensorboard dir:\", TB_ROOT)\n",
    "\n",
    "SKIP = False  # Skip all if a model is already tested?\n",
    "OVERWRITE = False  # Redoing the model selection for a model?\n",
    "BENCHMARKS_TRIALS = 10  # How many times do the benchmark. 0 to skip bechmark\n",
    "\n",
    "TUNER = \"BayesianOptimization\"  # \"Hyperband\" or \"BayesianOptimization\"\n",
    "\n",
    "MAX_UNITS = 400\n",
    "MAX_EPOCHS = 150\n",
    "PATIENCE = 10 # EarlyStopping\n",
    "TRIALS = 3  # int positive number of iteration for one set of hyperparameter\n",
    "\n",
    "MAX_TRIALS = 100  # BayesianOptimization\n",
    "\n",
    "#set the following values based on the specific dataset\n",
    "READOUT_ACTIVATION = keras.activations.softmax  # https://www.tensorflow.org/api_docs/python/tf/keras/activations  'softmax'\n",
    "LOSS_FUNCTION = keras.losses.SparseCategoricalCrossentropy()  # https://www.tensorflow.org/api_docs/python/tf/keras/losses  'sparse_categorical_crossentropy'\n",
    "\n",
    "if not os.path.exists(TUNER_ROOT):\n",
    "    os.makedirs(TUNER_ROOT)\n",
    "if not os.path.exists(TB_ROOT):\n",
    "    os.makedirs(TB_ROOT)\n",
    "\n",
    "benchmarks = BenchmarksDB(load_path=os.path.join(BENCHMARKS_ROOT, \"benchmarks.json\"), plot_path=WEIGHTS_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|        | ArticularyWordRecognition | CharacterTrajectories | Epilepsy | JapaneseVowels  | Libras | SpokenArabicDigits |\n",
    "|--------|:-------------------------:|:---------------------:|:--------:|:---------------:|:------:|:------------------:|\n",
    "| Input  |             9             |           3           |    3     |       12        |   2    |         13         |\n",
    "| Output |            25             |          20           |    4     |        9        |   15   |         10         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras_tuner import Hyperband, BayesianOptimization\n",
    "\n",
    "\n",
    "def model_selection(build_model_fn, names,\n",
    "                    train_set, val_set,\n",
    "                    tuner_path, verbose=1):\n",
    "    dataset_name, class_name, experiment_name, model_name = names\n",
    "    x_train, y_train = train_set\n",
    "    x_val, y_val = val_set\n",
    "    if TUNER == \"Hyperband\":\n",
    "        working_dir = os.path.join(tuner_path, \"Hyperband\", dataset_name, class_name)\n",
    "        if not os.path.exists(working_dir):\n",
    "            os.makedirs(working_dir)\n",
    "\n",
    "        tuner = Hyperband(\n",
    "            build_model_fn,\n",
    "            objective='val_accuracy',\n",
    "            max_epochs=MAX_EPOCHS,\n",
    "            hyperband_iterations=1.,\n",
    "            seed=42,\n",
    "\n",
    "            directory=working_dir,\n",
    "            project_name=experiment_name + ' ' + model_name,\n",
    "            overwrite=OVERWRITE,\n",
    "            executions_per_trial=TRIALS,\n",
    "        )\n",
    "    elif TUNER == \"BayesianOptimization\":\n",
    "        working_dir = os.path.join(tuner_path, \"BayesianOptimization\", dataset_name, class_name)\n",
    "        if not os.path.exists(working_dir):\n",
    "            os.makedirs(working_dir)\n",
    "\n",
    "        tuner = BayesianOptimization(\n",
    "            build_model_fn,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=MAX_TRIALS,\n",
    "            #num_initial_points=2,\n",
    "            seed=42,\n",
    "\n",
    "            directory=working_dir,\n",
    "            project_name=experiment_name + ' ' + model_name,\n",
    "            overwrite=OVERWRITE,\n",
    "            executions_per_trial=TRIALS,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Tuner -> {}\".format(TUNER))\n",
    "\n",
    "    # choose the best hyperparameters\n",
    "    tuner.search(x_train, y_train, epochs=MAX_EPOCHS, validation_data=(x_val, y_val),\n",
    "                 callbacks=[\n",
    "                     keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "                 ], verbose=verbose)\n",
    "    return tuner\n",
    "\n",
    "def testing_model(names, tuner, test_set,\n",
    "                  tensorboard_path=None, benchmarks_verbose=0):\n",
    "    dataset_name, class_name, experiment_name, model_name = names\n",
    "    x_test, y_test = test_set  # keras.callbacks.CallbackList([])\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)]\n",
    "    if tensorboard_path is not None:\n",
    "        tensorboard_dir = tensorboard_path + model_name\n",
    "        callbacks.append(keras.callbacks.TensorBoard(tensorboard_dir, profile_batch='500,500'))\n",
    "\n",
    "    print(\"Start {} benchmarks for {} | {} | {} | {}:\".format(BENCHMARKS_TRIALS, dataset_name, class_name, experiment_name,\n",
    "                                                              model_name))\n",
    "\n",
    "    best_model_hp = tuner.get_best_hyperparameters()[0]\n",
    "    test_model = None\n",
    "    best_acc = 0\n",
    "    best_tested = None\n",
    "    metrics_ts = []\n",
    "    loss_ts = []\n",
    "    required_time = []\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    for i in range(BENCHMARKS_TRIALS):\n",
    "        initial_time = time()\n",
    "\n",
    "        test_model = tuner.hypermodel.build(best_model_hp)\n",
    "        test_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=MAX_EPOCHS,\n",
    "                       callbacks=callbacks, verbose=benchmarks_verbose)\n",
    "        loss, metrics = test_model.evaluate(x_train, y_train)\n",
    "        if metrics > best_acc:\n",
    "            best_acc = metrics\n",
    "            best_tested = test_model\n",
    "        required_time.append(time() - initial_time)\n",
    "        metrics_ts.append(metrics)\n",
    "        loss_ts.append(loss)\n",
    "\n",
    "    stat = Statistic(best_model_hp, metrics_ts, loss_ts, required_time)\n",
    "\n",
    "    return best_tested, stat\n",
    "\n",
    "\n",
    "notify2_init = False\n",
    "\n",
    "\n",
    "def send_notification(title, message):\n",
    "    def notify2_init_fun():\n",
    "        global notify2_init\n",
    "        if not notify2_init:\n",
    "            notify2.init(\"Tesi\")\n",
    "\n",
    "    notify2_init_fun()\n",
    "\n",
    "    notice = notify2.Notification(title, message)\n",
    "    notice.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Local Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell is a little nightmare\n",
    "\n",
    "class HP:\n",
    "    FREE = 0\n",
    "    FIXED = 1\n",
    "    RESTRICTED = 2\n",
    "\n",
    "    def __init__(self, hp_type, value=None):\n",
    "        self.value = value\n",
    "        self.type = hp_type\n",
    "\n",
    "    @classmethod\n",
    "    def free(cls):\n",
    "        return cls(HP.FREE)\n",
    "\n",
    "    @classmethod\n",
    "    def fixed(cls, value):\n",
    "        return cls(HP.FIXED, value)\n",
    "\n",
    "    @classmethod\n",
    "    def restricted(cls, value=None):\n",
    "        return cls(HP.RESTRICTED, value)\n",
    "\n",
    "\n",
    "def get_int(tuner, name, hp, min_value, max_value, step=1, sampling=None, pn=None, pv=None):\n",
    "    if hp.type == HP.FREE or hp.type == HP.RESTRICTED:\n",
    "        tmp = tuner.Int(name, min_value=min_value, max_value=max_value, step=step, sampling=sampling, parent_name=pn,\n",
    "                        parent_values=pv)\n",
    "    elif hp.type == HP.FIXED:\n",
    "        tmp = tuner.Fixed(name, hp.value)\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_float(tuner, name, hp, min_value, max_value, step=None, sampling=None, pn=None, pv=None):\n",
    "    if hp.type == HP.FREE or (hp.type == HP.RESTRICTED and hp.value is None):\n",
    "        tmp = tuner.Float(name, min_value=min_value, max_value=max_value, step=step, sampling=sampling, parent_name=pn,\n",
    "                          parent_values=pv)\n",
    "    elif hp.type == HP.FIXED or (hp.type == HP.RESTRICTED and hp.value is not None):\n",
    "        tmp = tuner.Fixed(name, hp.value)\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_bool(tuner, name, hp):\n",
    "    if hp.type == HP.FREE or hp.type == HP.RESTRICTED:\n",
    "        tmp = tuner.Boolean(name)\n",
    "    elif hp.type == HP.FIXED:\n",
    "        tmp = tuner.Fixed(name, hp.value)\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_float_vec(tuner, name, hp, length, min_value, max_value, step=None, sampling=None, pn=None, pv=None):\n",
    "    if hp.type == HP.FREE:\n",
    "        tmp = [tuner.Float(name + ' ' + str(i), min_value=min_value, max_value=max_value, sampling=sampling,\n",
    "                           parent_name=pn, parent_values=pv, step=step)\n",
    "               for i in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        tmp = [tuner.Fixed(name + ' ' + str(i), hp.value[i]) for i in range(length)]\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        tmp2 = tuner.Float(name + ' 0', min_value=min_value, max_value=max_value, sampling=sampling, parent_name=pn,\n",
    "                               parent_values=pv, step=step)\n",
    "        tmp = [tmp2 for _ in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "def get_connectivity_esn1(tuner, hp):\n",
    "    if hp.type == HP.FREE:\n",
    "        tmp = tuner.Float('connectivity 0', min_value=0.1, max_value=1., step=0.1)\n",
    "    elif hp.type == HP.FIXED:\n",
    "        raise ValueError(\"HP.FIXED not valid for connectivity\")\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        tmp = tuner.Fixed('connectivity 0', hp.value)\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_connectivity_esn2(tuner, hp, length):\n",
    "    if hp.type == HP.FREE:\n",
    "        tmp = [tuner.Float('connectivity ' + str(i), min_value=0., max_value=1.) for i in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        raise ValueError(\"HP.FIXED not valid for connectivity\")\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        if hp.value is None:\n",
    "            tmp2 = tuner.Float('connectivity 0', min_value=0., max_value=1.)\n",
    "        else:\n",
    "            tmp2 = tuner.Fixed('connectivity 0', hp.value)\n",
    "        tmp = [tmp2 for _ in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return tmp\n",
    "\n",
    "def get_connectivity(tuner, hp, length):  # It is a squared matrix\n",
    "    if hp.type == HP.FREE:\n",
    "        conn_matrix = [[tuner.Float('connectivity ' + str(i), min_value=0., max_value=1., step = 0.1) if i == j else\n",
    "                        tuner.Float('connectivity ' + str(i) + '->' + str(j), min_value=0., max_value=1., step = 0.1)\n",
    "                        for i in range(length)]\n",
    "                       for j in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        diagonal, off_diagonal = hp.value\n",
    "        off_diagonal = tuner.Fixed('connectivity X->Y', off_diagonal)\n",
    "        conn_matrix = [[tuner.Fixed('connectivity ' + str(i), diagonal) if i == j else\n",
    "                        off_diagonal\n",
    "                        for i in range(length)]\n",
    "                       for j in range(length)]\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        if hp.value is None:\n",
    "            connectivity = [tuner.Float('connectivity ' + str(i), min_value=0., max_value=1., step=0.1) for i in range(length)]\n",
    "        else:\n",
    "            tmp = tuner.Fixed('connectivity 0', hp.value)\n",
    "            connectivity = [ tmp for _ in range(length)]\n",
    "        intra_connectivity = tuner.Float('connectivity X->Y', min_value=0., max_value=1., step=0.1)\n",
    "        conn_matrix = [[connectivity[i] if i == j else intra_connectivity for i in range(length)] for j in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return conn_matrix\n",
    "\n",
    "def get_minmax(tuner, hp, length):  # Is a matrix for ESN3 and ESN4\n",
    "    max_value = 2.0\n",
    "    if hp.type == HP.FREE:\n",
    "        minmax_vec = [[0. if i == j else tuner.Float('minmax ' + str(i) + '->' + str(j), min_value=0.1, max_value=max_value, step = 0.1)\n",
    "                   for i in range(length)]\n",
    "                  for j in range(length)]\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        minmax = tuner.Float('minmax', min_value=0.1, max_value=max_value, step = 0.1)\n",
    "        minmax_vec = [[0. if i == j else minmax\n",
    "                   for i in range(length)]\n",
    "                  for j in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        minmax = hp.value\n",
    "        minmax_vec = [[0. if i == j else minmax\n",
    "                   for i in range(length)]\n",
    "                  for j in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return minmax_vec\n",
    "\n",
    "def get_spectral_radius(tuner, hp, length):  # Is a vector\n",
    "    max_value = 2.0\n",
    "    if hp.type == HP.FREE:\n",
    "        sr_vec = [tuner.Float('spectral radius ' + str(i), min_value=0.1, max_value=max_value, step = 0.1) for i in range(length)]\n",
    "    elif hp.type == HP.RESTRICTED:\n",
    "        spectral_radius = tuner.Float('spectral radius 0', min_value=0.1, max_value=max_value, step = 0.1)\n",
    "        sr_vec = [spectral_radius for _ in range(length)]\n",
    "    elif hp.type == HP.FIXED:\n",
    "        spectral_radius = hp.value\n",
    "        sr_vec = [spectral_radius for _ in range(length)]\n",
    "    else:\n",
    "        raise ValueError(\"HP type not found\")\n",
    "    return sr_vec\n",
    "\n",
    "def get_gsr(tuner, gsr):\n",
    "    global_sr = get_bool(tuner, 'use G.S.R.', gsr)\n",
    "    if global_sr:\n",
    "        global_sr = tuner.Float('G.S.R.', min_value=0.1, max_value=2., parent_name='use G.S.R.', parent_values=True, step = 0.1)\n",
    "    else:\n",
    "        global_sr = None #  tuner.Fixed('G.S.R.', False, parent_name='use G.S.R.', parent_values=False)\n",
    "\n",
    "    return global_sr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build model functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_ESN1(output, _reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, _gsr, _off_diag, connectivity, input_scaling, bias_scaling, leaky, learning_rate,  # Defined by experiment\n",
    "               tuner) -> ESN1:\n",
    "    tmp_model = ESN1(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     connectivity=get_connectivity_esn1(tuner, connectivity),\n",
    "                     spectral_radius=get_float(tuner, 'spectral radius 0', spectral_radius, min_value=0.1, max_value=2., step = 0.1),\n",
    "                     output_units=output,\n",
    "                     readout_activation=READOUT_ACTIVATION,\n",
    "                     input_scaling=get_float(tuner, 'input scaling 0', input_scaling, min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=get_float(tuner, 'bias scaling 0', bias_scaling, min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.0, max_value=1., step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN2(output, reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, gsr, _off_diag, connectivity, input_scaling, bias_scaling, leaky, learning_rate,\n",
    "               # Defined by experiment\n",
    "               tuner) -> ESN2:\n",
    "    tmp_model = ESN2(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     sub_reservoirs=reservoirs,\n",
    "                     connectivity=get_connectivity_esn2(tuner, connectivity, reservoirs),\n",
    "                     spectral_radius=get_spectral_radius(tuner, spectral_radius, reservoirs),\n",
    "                     gsr=get_gsr(tuner, gsr),\n",
    "                     output_units=output,\n",
    "                     readout_activation=READOUT_ACTIVATION,\n",
    "                     input_scaling=get_float_vec(tuner, 'input scaling', input_scaling, reservoirs, min_value=0.1,\n",
    "                                                 max_value=1.5, step=0.1),\n",
    "                     bias_scaling=get_float_vec(tuner, 'bias scaling', bias_scaling, reservoirs, min_value=0.1,\n",
    "                                                max_value=1.5, step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.0, max_value=1., step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN3(output, reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, gsr, off_diag, connectivity, input_scaling, bias_scaling, leaky, learning_rate,\n",
    "               # Defined by experiment\n",
    "               tuner) -> ESN3:\n",
    "    tmp_model = ESN3(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     sub_reservoirs=reservoirs,\n",
    "                     connectivity=get_connectivity(tuner, connectivity, reservoirs),\n",
    "                     spectral_radius=get_spectral_radius(tuner, spectral_radius, reservoirs),\n",
    "                     gsr=get_gsr(tuner, gsr),\n",
    "                     off_diagonal=get_minmax(tuner, off_diag, reservoirs),\n",
    "                     output_units=output,\n",
    "                     readout_activation=READOUT_ACTIVATION,\n",
    "                     input_scaling=get_float_vec(tuner, 'input scaling', input_scaling, reservoirs, min_value=0.1,\n",
    "                                                 max_value=1.5, step=0.1),\n",
    "                     bias_scaling=get_float_vec(tuner, 'bias scaling', bias_scaling, reservoirs, min_value=0.1,\n",
    "                                                max_value=1.5, step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.0, max_value=1., step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),  # keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN4(output, reservoirs,  # Defined by dataset\n",
    "               units, spectral_radius, gsr, off_diag, connectivity, input_scaling, bias_scaling, leaky, learning_rate,\n",
    "               # Defined by experiment\n",
    "               tuner) -> ESN4:\n",
    "    partitions = [tuner.Float('partition ' + str(i), min_value=0.1, max_value=1.0, step=0.333) for i in range(reservoirs)]\n",
    "    total = sum(partitions)\n",
    "    # Normalize the partition vector now sum(partitions) == 1.\n",
    "    partitions = list(map(lambda _x: 0 if total == 0 else _x / total, partitions))\n",
    "    tmp_model = ESN4(units=get_int(tuner, 'units', units, 50, MAX_UNITS),\n",
    "                     sub_reservoirs=reservoirs,\n",
    "                     connectivity=get_connectivity(tuner, connectivity, reservoirs),\n",
    "                     partitions=partitions,\n",
    "                     spectral_radius=get_spectral_radius(tuner, spectral_radius, reservoirs),\n",
    "                     gsr=get_gsr(tuner, gsr),\n",
    "                     off_diagonal=get_minmax(tuner, off_diag, reservoirs),\n",
    "                     output_units=output,\n",
    "                     readout_activation=READOUT_ACTIVATION,\n",
    "                     input_scaling=get_float_vec(tuner, 'input scaling', input_scaling, reservoirs, min_value=0.1,\n",
    "                                                 max_value=1.5, step=0.1),\n",
    "                     bias_scaling=get_float_vec(tuner, 'bias scaling', bias_scaling, reservoirs, min_value=0.1,\n",
    "                                                max_value=1.5, step=0.1),\n",
    "                     leaky=get_float(tuner, 'leaky', leaky, min_value=0.0, max_value=1., step=0.1),\n",
    "                     )\n",
    "\n",
    "    alpha = get_float(tuner, 'learning rate', learning_rate, min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(alpha),# keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return tmp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'Datasets': [\n",
    "        # \"ArticularyWordRecognition\",\n",
    "        \"CharacterTrajectories\",\n",
    "        # \"Libras\",\n",
    "        # \"SpokenArabicDigits\",\n",
    "        # \"Epilepsy\",\n",
    "        # \"JapaneseVowels\"\n",
    "    ],\n",
    "    'Classes': [\n",
    "        # \"Best Models\",\n",
    "        \"Multiple S.R.\",\n",
    "        # \"Single S.R.\"\n",
    "    ],\n",
    "    'Models': [\n",
    "        build_ESN1,\n",
    "        build_ESN2,\n",
    "        build_ESN3,\n",
    "        build_ESN4\n",
    "    ],\n",
    "    #                Units         | Spectral radius | G.S.R.    | off-diag      | Connectivity     | Input scaling  | Bias scaling   | leaky    | learning rate\n",
    "    #                F             | F-R             | F         | F - R         | F - R            | F-R            | F-R            | F        | F\n",
    "    'Best Models': {\n",
    "        'Best':      (HP.free(),     HP.free(),      HP.free(),  HP.restricted(), HP.restricted(),   HP.free(),       HP.free(),       HP.free(), HP.free())\n",
    "    },\n",
    "    'Multiple S.R.': {  # Modello con N sub res ora ha 7 + N ( N diag sr + 1 off diag st, 1 g.s.r., 1 off-diag conn, 1 input, 1 bias, 1 leaky, 1 learning)\n",
    "         'Units 50': (HP.fixed(50),  HP.free(),       HP.fixed(False), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "         'Units 75': (HP.fixed(75),  HP.free(),       HP.fixed(False), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 100': (HP.fixed(100), HP.free(),       HP.fixed(False), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 150': (HP.fixed(150), HP.free(),       HP.fixed(False), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 250': (HP.fixed(250), HP.free(),       HP.fixed(False), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    },\n",
    "    'Single S.R.': {\n",
    "         'Units 50': (HP.fixed(50),  HP.restricted(), HP.free(), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "         'Units 75': (HP.fixed(75),  HP.restricted(), HP.free(), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 100': (HP.fixed(100), HP.restricted(), HP.free(), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 150': (HP.fixed(150), HP.restricted(), HP.free(), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "        'Units 250': (HP.fixed(250), HP.restricted(), HP.free(), HP.restricted(), HP.restricted(1.), HP.restricted(), HP.restricted(), HP.free(), HP.free()),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n",
      "/dati/luca/Uni-Luca/Tesi/progetto/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 50', 'ESN1')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN1/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN1/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 50 | ESN1:\n",
      "30/30 [==============================] - 0s 357us/step - loss: 0.8822 - accuracy: 0.7185\n",
      "30/30 [==============================] - 0s 364us/step - loss: 0.6236 - accuracy: 0.8130\n",
      "30/30 [==============================] - 0s 475us/step - loss: 0.6138 - accuracy: 0.8267\n",
      "30/30 [==============================] - 0s 391us/step - loss: 0.7559 - accuracy: 0.7826\n",
      "30/30 [==============================] - 0s 542us/step - loss: 0.7126 - accuracy: 0.7815\n",
      "30/30 [==============================] - 0s 376us/step - loss: 0.6806 - accuracy: 0.8109\n",
      "30/30 [==============================] - 0s 471us/step - loss: 0.7221 - accuracy: 0.7826\n",
      "30/30 [==============================] - 0s 391us/step - loss: 0.8001 - accuracy: 0.7521\n",
      "30/30 [==============================] - 0s 347us/step - loss: 0.6928 - accuracy: 0.7941\n",
      "30/30 [==============================] - 0s 403us/step - loss: 0.6629 - accuracy: 0.7836\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 50', 'ESN2')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN2/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN2/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 50 | ESN2:\n",
      "30/30 [==============================] - 0s 598us/step - loss: 0.4531 - accuracy: 0.8824\n",
      "30/30 [==============================] - 0s 355us/step - loss: 0.3967 - accuracy: 0.8792\n",
      "30/30 [==============================] - 0s 391us/step - loss: 0.2745 - accuracy: 0.9233\n",
      "30/30 [==============================] - 0s 386us/step - loss: 0.4062 - accuracy: 0.8918\n",
      "30/30 [==============================] - 0s 416us/step - loss: 0.3177 - accuracy: 0.9086\n",
      "30/30 [==============================] - 0s 495us/step - loss: 0.2649 - accuracy: 0.9275\n",
      "30/30 [==============================] - 0s 485us/step - loss: 0.4055 - accuracy: 0.8887\n",
      "30/30 [==============================] - 0s 403us/step - loss: 0.3433 - accuracy: 0.9002\n",
      "30/30 [==============================] - 0s 378us/step - loss: 0.2576 - accuracy: 0.9370\n",
      "30/30 [==============================] - 0s 394us/step - loss: 0.2433 - accuracy: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 50', 'ESN3')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN3/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN3/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 50 | ESN3:\n",
      "30/30 [==============================] - 0s 377us/step - loss: 0.6385 - accuracy: 0.8078\n",
      "30/30 [==============================] - 0s 427us/step - loss: 0.6677 - accuracy: 0.7931\n",
      "30/30 [==============================] - 0s 383us/step - loss: 0.4912 - accuracy: 0.8351\n",
      "30/30 [==============================] - 0s 467us/step - loss: 0.5358 - accuracy: 0.8361\n",
      "30/30 [==============================] - 0s 390us/step - loss: 0.6709 - accuracy: 0.7847\n",
      "30/30 [==============================] - 0s 378us/step - loss: 0.5130 - accuracy: 0.8487\n",
      "30/30 [==============================] - 0s 360us/step - loss: 0.7012 - accuracy: 0.7773\n",
      "30/30 [==============================] - 0s 520us/step - loss: 0.7728 - accuracy: 0.7563\n",
      "30/30 [==============================] - 0s 534us/step - loss: 0.6488 - accuracy: 0.7836\n",
      "30/30 [==============================] - 0s 357us/step - loss: 0.4125 - accuracy: 0.8645\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 50', 'ESN4')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN4/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 50 ESN4/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 50 | ESN4:\n",
      "30/30 [==============================] - 0s 532us/step - loss: 0.6306 - accuracy: 0.7899\n",
      "30/30 [==============================] - 0s 522us/step - loss: 0.5029 - accuracy: 0.8592\n",
      "30/30 [==============================] - 0s 524us/step - loss: 0.6292 - accuracy: 0.8246\n",
      "30/30 [==============================] - 0s 457us/step - loss: 0.4614 - accuracy: 0.8561\n",
      "30/30 [==============================] - 0s 481us/step - loss: 0.3339 - accuracy: 0.8981\n",
      "30/30 [==============================] - 0s 354us/step - loss: 0.5789 - accuracy: 0.8183\n",
      "30/30 [==============================] - 0s 390us/step - loss: 0.5006 - accuracy: 0.8445\n",
      "30/30 [==============================] - 0s 371us/step - loss: 0.4972 - accuracy: 0.8519\n",
      "30/30 [==============================] - 0s 490us/step - loss: 0.4263 - accuracy: 0.8845\n",
      "30/30 [==============================] - 0s 536us/step - loss: 0.3190 - accuracy: 0.9055\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 75', 'ESN1')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN1/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN1/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 75 | ESN1:\n",
      "30/30 [==============================] - 0s 379us/step - loss: 0.1670 - accuracy: 0.9496\n",
      "30/30 [==============================] - 0s 380us/step - loss: 0.1325 - accuracy: 0.9601\n",
      "30/30 [==============================] - 0s 378us/step - loss: 0.7314 - accuracy: 0.7731\n",
      "30/30 [==============================] - 0s 544us/step - loss: 0.1553 - accuracy: 0.9580\n",
      "30/30 [==============================] - 0s 377us/step - loss: 0.2121 - accuracy: 0.9359\n",
      "30/30 [==============================] - 0s 348us/step - loss: 0.3188 - accuracy: 0.9002\n",
      "30/30 [==============================] - 0s 425us/step - loss: 0.2984 - accuracy: 0.9139\n",
      "30/30 [==============================] - 0s 486us/step - loss: 0.2090 - accuracy: 0.9412\n",
      "30/30 [==============================] - 0s 410us/step - loss: 0.0952 - accuracy: 0.9769\n",
      "30/30 [==============================] - 0s 600us/step - loss: 0.1904 - accuracy: 0.9517\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 75', 'ESN2')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN2/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN2/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 75 | ESN2:\n",
      "30/30 [==============================] - 0s 411us/step - loss: 0.6184 - accuracy: 0.8708\n",
      "30/30 [==============================] - 0s 483us/step - loss: 0.3699 - accuracy: 0.9170\n",
      "30/30 [==============================] - 0s 440us/step - loss: 0.8348 - accuracy: 0.7973\n",
      "30/30 [==============================] - 0s 566us/step - loss: 0.4449 - accuracy: 0.9044\n",
      "30/30 [==============================] - 0s 351us/step - loss: 0.5457 - accuracy: 0.8750\n",
      "30/30 [==============================] - 0s 457us/step - loss: 0.2823 - accuracy: 0.9412\n",
      "30/30 [==============================] - 0s 355us/step - loss: 0.4034 - accuracy: 0.9170\n",
      "30/30 [==============================] - 0s 523us/step - loss: 0.5241 - accuracy: 0.8792\n",
      "30/30 [==============================] - 0s 546us/step - loss: 0.4617 - accuracy: 0.8845\n",
      "30/30 [==============================] - 0s 423us/step - loss: 0.7212 - accuracy: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 75', 'ESN3')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN3/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN3/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 75 | ESN3:\n",
      "30/30 [==============================] - 0s 354us/step - loss: 0.2888 - accuracy: 0.9013\n",
      "30/30 [==============================] - 0s 447us/step - loss: 0.3984 - accuracy: 0.8771\n",
      "30/30 [==============================] - 0s 360us/step - loss: 0.3896 - accuracy: 0.8918\n",
      "30/30 [==============================] - 0s 454us/step - loss: 0.3509 - accuracy: 0.8887\n",
      "30/30 [==============================] - 0s 500us/step - loss: 0.3825 - accuracy: 0.8687\n",
      "30/30 [==============================] - 0s 419us/step - loss: 0.2174 - accuracy: 0.9307\n",
      "30/30 [==============================] - 0s 390us/step - loss: 0.3822 - accuracy: 0.8729\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.2610 - accuracy: 0.9118\n",
      "30/30 [==============================] - 0s 372us/step - loss: 0.2054 - accuracy: 0.9296\n",
      "30/30 [==============================] - 0s 374us/step - loss: 0.2682 - accuracy: 0.9139\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 75', 'ESN4')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN4/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 75 ESN4/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 75 | ESN4:\n",
      "30/30 [==============================] - 0s 389us/step - loss: 0.2645 - accuracy: 0.9401\n",
      "30/30 [==============================] - 0s 503us/step - loss: 0.3835 - accuracy: 0.9034\n",
      "30/30 [==============================] - 0s 527us/step - loss: 0.3238 - accuracy: 0.9128\n",
      "30/30 [==============================] - 0s 367us/step - loss: 0.3176 - accuracy: 0.9118\n",
      "30/30 [==============================] - 0s 504us/step - loss: 0.4048 - accuracy: 0.8929\n",
      "30/30 [==============================] - 0s 377us/step - loss: 0.4364 - accuracy: 0.8676\n",
      "30/30 [==============================] - 0s 571us/step - loss: 0.2978 - accuracy: 0.9202\n",
      "30/30 [==============================] - 0s 383us/step - loss: 0.3469 - accuracy: 0.9013\n",
      "30/30 [==============================] - 0s 371us/step - loss: 0.3412 - accuracy: 0.9149\n",
      "30/30 [==============================] - 0s 493us/step - loss: 0.2920 - accuracy: 0.9212\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 100', 'ESN1')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN1/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN1/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 100 | ESN1:\n",
      "30/30 [==============================] - 0s 363us/step - loss: 0.0441 - accuracy: 0.9926\n",
      "30/30 [==============================] - 0s 659us/step - loss: 0.0622 - accuracy: 0.9853\n",
      "30/30 [==============================] - 0s 487us/step - loss: 0.0892 - accuracy: 0.9800\n",
      "30/30 [==============================] - 0s 568us/step - loss: 0.1493 - accuracy: 0.9569\n",
      "30/30 [==============================] - 0s 412us/step - loss: 0.1417 - accuracy: 0.9622\n",
      "30/30 [==============================] - 0s 382us/step - loss: 0.0697 - accuracy: 0.9832\n",
      "30/30 [==============================] - 0s 512us/step - loss: 0.0882 - accuracy: 0.9790\n",
      "30/30 [==============================] - 0s 540us/step - loss: 0.1479 - accuracy: 0.9632\n",
      "30/30 [==============================] - 0s 513us/step - loss: 0.0844 - accuracy: 0.9800\n",
      "30/30 [==============================] - 0s 452us/step - loss: 0.0867 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 100', 'ESN2')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN2/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN2/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 100 | ESN2:\n",
      "30/30 [==============================] - 0s 362us/step - loss: 0.1213 - accuracy: 0.9674\n",
      "30/30 [==============================] - 0s 390us/step - loss: 0.1864 - accuracy: 0.9443\n",
      "30/30 [==============================] - 0s 572us/step - loss: 0.1880 - accuracy: 0.9464\n",
      "30/30 [==============================] - 0s 341us/step - loss: 0.2459 - accuracy: 0.9338\n",
      "30/30 [==============================] - 0s 497us/step - loss: 0.1592 - accuracy: 0.9569\n",
      "30/30 [==============================] - 0s 428us/step - loss: 0.2412 - accuracy: 0.9296\n",
      "30/30 [==============================] - 0s 373us/step - loss: 0.1538 - accuracy: 0.9632\n",
      "30/30 [==============================] - 0s 666us/step - loss: 0.2645 - accuracy: 0.9265\n",
      "30/30 [==============================] - 0s 467us/step - loss: 0.2822 - accuracy: 0.9149\n",
      "30/30 [==============================] - 0s 400us/step - loss: 0.2103 - accuracy: 0.9307\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 100', 'ESN3')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN3/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN3/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 100 | ESN3:\n",
      "30/30 [==============================] - 0s 399us/step - loss: 1.6220 - accuracy: 0.4706\n",
      "30/30 [==============================] - 0s 374us/step - loss: 1.6063 - accuracy: 0.4475\n",
      "30/30 [==============================] - 0s 366us/step - loss: 1.6658 - accuracy: 0.4527\n",
      "30/30 [==============================] - 0s 503us/step - loss: 1.6654 - accuracy: 0.4328\n",
      "30/30 [==============================] - 0s 376us/step - loss: 1.6900 - accuracy: 0.4422\n",
      "30/30 [==============================] - 0s 357us/step - loss: 1.6961 - accuracy: 0.4559\n",
      "30/30 [==============================] - 0s 354us/step - loss: 1.7008 - accuracy: 0.4202\n",
      "30/30 [==============================] - 0s 363us/step - loss: 1.7075 - accuracy: 0.4328\n",
      "30/30 [==============================] - 0s 361us/step - loss: 1.4513 - accuracy: 0.5284\n",
      "30/30 [==============================] - 0s 542us/step - loss: 1.7241 - accuracy: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 100', 'ESN4')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN4/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 100 ESN4/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 100 | ESN4:\n",
      "30/30 [==============================] - 0s 394us/step - loss: 1.0168 - accuracy: 0.6817\n",
      "30/30 [==============================] - 0s 556us/step - loss: 0.9043 - accuracy: 0.7437\n",
      "30/30 [==============================] - 0s 484us/step - loss: 1.0927 - accuracy: 0.6828\n",
      "30/30 [==============================] - 0s 451us/step - loss: 1.1632 - accuracy: 0.6408\n",
      "30/30 [==============================] - 0s 501us/step - loss: 1.1139 - accuracy: 0.6565\n",
      "30/30 [==============================] - 0s 652us/step - loss: 1.1084 - accuracy: 0.6870\n",
      "30/30 [==============================] - 0s 478us/step - loss: 1.3400 - accuracy: 0.6250\n",
      "30/30 [==============================] - 0s 368us/step - loss: 1.2636 - accuracy: 0.6376\n",
      "30/30 [==============================] - 0s 421us/step - loss: 1.1032 - accuracy: 0.7164\n",
      "30/30 [==============================] - 0s 370us/step - loss: 1.3006 - accuracy: 0.6050\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 150', 'ESN1')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN1/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN1/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 150 | ESN1:\n",
      "30/30 [==============================] - 0s 349us/step - loss: 0.1766 - accuracy: 0.9559\n",
      "30/30 [==============================] - 0s 370us/step - loss: 0.1801 - accuracy: 0.9601\n",
      "30/30 [==============================] - 0s 471us/step - loss: 0.2482 - accuracy: 0.9443\n",
      "30/30 [==============================] - 0s 489us/step - loss: 0.1246 - accuracy: 0.9758\n",
      "30/30 [==============================] - 0s 552us/step - loss: 0.2087 - accuracy: 0.9559\n",
      "30/30 [==============================] - 0s 485us/step - loss: 0.1198 - accuracy: 0.9737\n",
      "30/30 [==============================] - 0s 510us/step - loss: 0.1264 - accuracy: 0.9737\n",
      "30/30 [==============================] - 0s 356us/step - loss: 0.1049 - accuracy: 0.9800\n",
      "30/30 [==============================] - 0s 465us/step - loss: 0.0919 - accuracy: 0.9800\n",
      "30/30 [==============================] - 0s 432us/step - loss: 0.1788 - accuracy: 0.9611\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 150', 'ESN2')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN2/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN2/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 150 | ESN2:\n",
      "30/30 [==============================] - 0s 494us/step - loss: 0.1419 - accuracy: 0.9643\n",
      "30/30 [==============================] - 0s 500us/step - loss: 0.2373 - accuracy: 0.9296\n",
      "30/30 [==============================] - 0s 567us/step - loss: 0.1812 - accuracy: 0.9538\n",
      "30/30 [==============================] - 0s 385us/step - loss: 0.0476 - accuracy: 0.9916\n",
      "30/30 [==============================] - 0s 376us/step - loss: 0.1166 - accuracy: 0.9779\n",
      "30/30 [==============================] - 0s 386us/step - loss: 0.1292 - accuracy: 0.9716\n",
      "30/30 [==============================] - 0s 481us/step - loss: 0.1518 - accuracy: 0.9664\n",
      "30/30 [==============================] - 0s 365us/step - loss: 0.1529 - accuracy: 0.9643\n",
      "30/30 [==============================] - 0s 372us/step - loss: 0.2162 - accuracy: 0.9370\n",
      "30/30 [==============================] - 0s 367us/step - loss: 0.1343 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 150', 'ESN3')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN3/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN3/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 150 | ESN3:\n",
      "30/30 [==============================] - 0s 498us/step - loss: 1.0189 - accuracy: 0.6870\n",
      "30/30 [==============================] - 0s 451us/step - loss: 1.1067 - accuracy: 0.6817\n",
      "30/30 [==============================] - 0s 523us/step - loss: 1.2821 - accuracy: 0.6408\n",
      "30/30 [==============================] - 0s 379us/step - loss: 0.6716 - accuracy: 0.8130\n",
      "30/30 [==============================] - 0s 494us/step - loss: 0.8585 - accuracy: 0.7458\n",
      "30/30 [==============================] - 0s 379us/step - loss: 0.8963 - accuracy: 0.7185\n",
      "30/30 [==============================] - 0s 361us/step - loss: 1.0241 - accuracy: 0.7437\n",
      "30/30 [==============================] - 0s 388us/step - loss: 1.3882 - accuracy: 0.6324\n",
      "30/30 [==============================] - 0s 346us/step - loss: 1.0004 - accuracy: 0.6985\n",
      "30/30 [==============================] - 0s 503us/step - loss: 0.7923 - accuracy: 0.7542\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 150', 'ESN4')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN4/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 150 ESN4/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 150 | ESN4:\n",
      "30/30 [==============================] - 0s 487us/step - loss: 0.0715 - accuracy: 0.9842\n",
      "30/30 [==============================] - 0s 558us/step - loss: 0.1552 - accuracy: 0.9580\n",
      "30/30 [==============================] - 0s 375us/step - loss: 0.1035 - accuracy: 0.9737\n",
      "30/30 [==============================] - 0s 347us/step - loss: 0.0708 - accuracy: 0.9832\n",
      "30/30 [==============================] - 0s 360us/step - loss: 0.1126 - accuracy: 0.9790\n",
      "30/30 [==============================] - 0s 344us/step - loss: 0.0790 - accuracy: 0.9884\n",
      "30/30 [==============================] - 0s 371us/step - loss: 0.1104 - accuracy: 0.9727\n",
      "30/30 [==============================] - 0s 353us/step - loss: 0.0752 - accuracy: 0.9853\n",
      "30/30 [==============================] - 0s 483us/step - loss: 0.0787 - accuracy: 0.9811\n",
      "30/30 [==============================] - 0s 387us/step - loss: 0.0638 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 250', 'ESN1')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN1/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN1/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 250 | ESN1:\n",
      "30/30 [==============================] - 0s 375us/step - loss: 0.0399 - accuracy: 0.9895\n",
      "30/30 [==============================] - 0s 382us/step - loss: 0.0387 - accuracy: 0.9916\n",
      "30/30 [==============================] - 0s 362us/step - loss: 0.0173 - accuracy: 1.0000\n",
      "30/30 [==============================] - 0s 542us/step - loss: 0.0156 - accuracy: 0.9979\n",
      "30/30 [==============================] - 0s 369us/step - loss: 0.0284 - accuracy: 0.9947\n",
      "30/30 [==============================] - 0s 382us/step - loss: 0.0237 - accuracy: 0.9979\n",
      "30/30 [==============================] - 0s 368us/step - loss: 0.0279 - accuracy: 0.9958\n",
      "30/30 [==============================] - 0s 379us/step - loss: 0.0452 - accuracy: 0.9905\n",
      "30/30 [==============================] - 0s 364us/step - loss: 0.0296 - accuracy: 0.9937\n",
      "30/30 [==============================] - 0s 356us/step - loss: 0.0297 - accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 250', 'ESN2')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN2/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN2/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 250 | ESN2:\n",
      "30/30 [==============================] - 0s 390us/step - loss: 0.0274 - accuracy: 0.9968\n",
      "30/30 [==============================] - 0s 402us/step - loss: 0.0793 - accuracy: 0.9853\n",
      "30/30 [==============================] - 0s 371us/step - loss: 0.0604 - accuracy: 0.9884\n",
      "30/30 [==============================] - 0s 382us/step - loss: 0.0447 - accuracy: 0.9895\n",
      "30/30 [==============================] - 0s 377us/step - loss: 0.0910 - accuracy: 0.9821\n",
      "30/30 [==============================] - 0s 387us/step - loss: 0.0367 - accuracy: 0.9905\n",
      "30/30 [==============================] - 0s 409us/step - loss: 0.0474 - accuracy: 0.9832\n",
      "30/30 [==============================] - 0s 382us/step - loss: 0.0555 - accuracy: 0.9874\n",
      "30/30 [==============================] - 0s 395us/step - loss: 0.0396 - accuracy: 0.9916\n",
      "30/30 [==============================] - 0s 378us/step - loss: 0.0791 - accuracy: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 250', 'ESN3')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN3/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN3/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 250 | ESN3:\n",
      "30/30 [==============================] - 0s 512us/step - loss: 0.2153 - accuracy: 0.9433\n",
      "30/30 [==============================] - 0s 480us/step - loss: 0.2468 - accuracy: 0.9328\n",
      "30/30 [==============================] - 0s 530us/step - loss: 0.2001 - accuracy: 0.9443\n",
      "30/30 [==============================] - 0s 400us/step - loss: 0.2282 - accuracy: 0.9380\n",
      "30/30 [==============================] - 0s 420us/step - loss: 0.2673 - accuracy: 0.9233\n",
      "30/30 [==============================] - 0s 395us/step - loss: 0.1720 - accuracy: 0.9485\n",
      "30/30 [==============================] - 0s 511us/step - loss: 0.1379 - accuracy: 0.9674\n",
      "30/30 [==============================] - 0s 374us/step - loss: 0.2067 - accuracy: 0.9391\n",
      "30/30 [==============================] - 0s 387us/step - loss: 0.2297 - accuracy: 0.9370\n",
      "30/30 [==============================] - 0s 510us/step - loss: 0.1861 - accuracy: 0.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": "('CharacterTrajectories', 'Multiple S.R.', 'Units 250', 'ESN4')"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN4/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/progetto/models/BayesianOptimization/CharacterTrajectories/Multiple S.R./Units 250 ESN4/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks for CharacterTrajectories | Multiple S.R. | Units 250 | ESN4:\n",
      "30/30 [==============================] - 0s 401us/step - loss: 0.1381 - accuracy: 0.9664\n",
      "30/30 [==============================] - 0s 365us/step - loss: 0.1474 - accuracy: 0.9643\n",
      "30/30 [==============================] - 0s 402us/step - loss: 0.1517 - accuracy: 0.9569\n",
      "30/30 [==============================] - 0s 373us/step - loss: 0.3314 - accuracy: 0.9464\n",
      "30/30 [==============================] - 0s 379us/step - loss: 0.1332 - accuracy: 0.9685\n",
      "30/30 [==============================] - 0s 412us/step - loss: 0.1022 - accuracy: 0.9821\n",
      "30/30 [==============================] - 0s 397us/step - loss: 0.0869 - accuracy: 0.9821\n",
      "30/30 [==============================] - 0s 378us/step - loss: 0.1635 - accuracy: 0.9548\n",
      "30/30 [==============================] - 0s 367us/step - loss: 0.1277 - accuracy: 0.9748\n",
      "30/30 [==============================] - 0s 556us/step - loss: 0.0871 - accuracy: 0.9716\n",
      "Total learning time:759.9274864196777\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "datasets = config.get('Datasets')\n",
    "classes = config.get('Classes')\n",
    "models_fn = config.get('Models')\n",
    "\n",
    "run_time = time()\n",
    "for dataset in datasets:\n",
    "    train_path = os.path.join(DATA_ROOT, dataset, dataset + '_TRAIN.ts')\n",
    "    test_path = os.path.join(DATA_ROOT, dataset, dataset + '_TEST.ts')\n",
    "\n",
    "    x_train_all, y_train_all = load_sktime_dataset(train_path)\n",
    "    x_test, y_test = load_sktime_dataset(test_path)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                      test_size=0.33, random_state=42, stratify=y_train_all)\n",
    "\n",
    "    train_set = (x_train, y_train)  # Todo is this cast necessary?\n",
    "    val_set = (x_val, y_val)\n",
    "    test_set = (x_test, y_test)\n",
    "\n",
    "    features = x_train.shape[-1]\n",
    "    output_units = len(np.unique(y_test))  # Dataset must have one of each features\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_time = time()\n",
    "        for experiment, params in config.get(class_name).items():\n",
    "            for model_fn in models_fn:\n",
    "                model_name = model_fn.__annotations__['return'].__name__\n",
    "                already_tested = benchmarks.is_benchmarked(dataset, class_name, experiment, model_name)\n",
    "\n",
    "                if already_tested and SKIP:\n",
    "                    continue\n",
    "\n",
    "                build_fn = partial(model_fn, output_units, features, *params)\n",
    "                names = (dataset, class_name, experiment, model_name)\n",
    "                display(names)\n",
    "\n",
    "                tuner = model_selection(build_fn, names,\n",
    "                                        train_set, val_set,\n",
    "                                        tuner_path=TUNER_ROOT, verbose=1)\n",
    "\n",
    "                if BENCHMARKS_TRIALS > 0:\n",
    "                    model, stat = testing_model(names, tuner, test_set)\n",
    "                    benchmarks.add(dataset, class_name, experiment, model_name, stat)\n",
    "                    #model.plot(names, path=WEIGHTS_ROOT, show=False)\n",
    "\n",
    "        # benchmarks.save()\n",
    "        # send_notification(class_name + \" done\", \"Requested time:\" + str(time() - class_time))\n",
    "\n",
    "print(\"Total learning time:\" + str(time() - run_time))\n",
    "send_notification(\"All Done\", \"Requested time:\" + str(time() - run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "benchmarks.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}