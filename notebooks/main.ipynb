{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Data dir: /dati/luca/Uni-Luca/Tesi/tesi/data\n",
      "      Tuner dir: /dati/luca/Uni-Luca/Tesi/tesi/models/tuner\n",
      "Tensorboard dir: /tmp/tensorboard\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from functools import *\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd() + os.sep + os.pardir)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from lib.time_series_datasets import *\n",
    "from lib.models import *\n",
    "from lib.utility import *\n",
    "\n",
    "DATA_ROOT  = os.path.join(PROJECT_ROOT, \"data\")\n",
    "TUNER_ROOT = os.path.join(PROJECT_ROOT, \"models\", \"tuner\")\n",
    "IMAGE_ROOT = os.path.join(PROJECT_ROOT, \"images\")\n",
    "TB_ROOT    = os.path.join(os.path.abspath(os.sep), \"tmp\", \"tensorboard\")\n",
    "\n",
    "BENCHMARKS_DIR = \"benchmarks\"\n",
    "WEIGHTS_DIR = \"weights\"\n",
    "\n",
    "print(\"       Data dir:\", DATA_ROOT)\n",
    "print(\"      Tuner dir:\", TUNER_ROOT)\n",
    "print(\"Tensorboard dir:\", TB_ROOT)\n",
    "\n",
    "SKIP = False\n",
    "\n",
    "MAX_UNITS = 400\n",
    "EPOCHS = 200\n",
    "GUESSES = 10\n",
    "PATIENCE = 10\n",
    "\n",
    "#set the following values based on the specific dataset\n",
    "OUTPUT_ACTIVATION = tf.keras.activations.softmax  # https://www.tensorflow.org/api_docs/python/tf/keras/activations  'softmax'\n",
    "LOSS_FUNCTION = tf.keras.losses.SparseCategoricalCrossentropy()  # https://www.tensorflow.org/api_docs/python/tf/keras/losses  'sparse_categorical_crossentropy'\n",
    "\n",
    "if not os.path.exists(TUNER_ROOT):\n",
    "    os.makedirs(TUNER_ROOT)\n",
    "if not os.path.exists(TB_ROOT):\n",
    "    os.makedirs(TB_ROOT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "|        | ArticularyWordRecognition | CharacterTrajectories | Libras | SpokenArabicDigits |\n",
    "|--------|:-------------------------:|:---------------------:|:------:|:------------------:|\n",
    "| Input  |             9             |           3           |   2    |         13         |\n",
    "| Output |            25             |          20           |   15   |         10         |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 2\n",
      "Output classes: 15\n",
      "Train shape:\n",
      "\tinput: (120, 45, 2)\n",
      "\toutput: (120,)\n",
      "Validation shape:\n",
      "\tinput: (60, 45, 2)\n",
      "\toutput: (60,)\n",
      "Test shape:\n",
      "\tinput: (180, 45, 2)\n",
      "\toutput: (180,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "DATASETS_NAMES = [\"ArticularyWordRecognition\", \"CharacterTrajectories\", \"Libras\", \"SpokenArabicDigits\"]\n",
    "dataset_name = DATASETS_NAMES[2]\n",
    "\n",
    "train_path  = os.path.join(DATA_ROOT, dataset_name, dataset_name + '_TRAIN.ts')\n",
    "test_path = os.path.join(DATA_ROOT, dataset_name, dataset_name + '_TEST.ts')\n",
    "\n",
    "x_train_all, y_train_all = load_sktime_dataset(train_path)  # Max shape serve per avere il test set e il train set della stessa lunghezza\n",
    "x_test, y_test = load_sktime_dataset(test_path)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, test_size=0.33, random_state=42, stratify=y_train_all)\n",
    "\n",
    "train_set = (x_train.astype(np.float64), y_train.astype(np.float64))\n",
    "val_set = (x_val.astype(np.float64), y_val.astype(np.float64))\n",
    "test_set = (x_test.astype(np.float64), y_test.astype(np.float64))\n",
    "\n",
    "features = x_train.shape[-1]\n",
    "output_units = len(np.unique(y_test))  # Dataset must have one of each features\n",
    "\n",
    "print(\"Input features: {}\".format(features))\n",
    "print(\"Output classes: {}\".format(output_units))\n",
    "print(\"Train shape:\\n\\tinput: {}\\n\\toutput: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"Validation shape:\\n\\tinput: {}\\n\\toutput: {}\".format(x_val.shape, y_val.shape))\n",
    "print(\"Test shape:\\n\\tinput: {}\\n\\toutput: {}\".format(x_test.shape, y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_dir(root, _dataset_name):\n",
    "    _path = os.path.join(root, _dataset_name)\n",
    "    if not os.path.exists(_path):\n",
    "        os.makedirs(_path)\n",
    "    return _path\n",
    "\n",
    "tuner_path = create_dir(TUNER_ROOT, dataset_name)\n",
    "image_path = create_dir(IMAGE_ROOT, dataset_name)\n",
    "benchmarks_path = create_dir(image_path, BENCHMARKS_DIR)\n",
    "json_path = os.path.join(benchmarks_path, \"benchmarks.json\")\n",
    "weight_path = create_dir(image_path, WEIGHTS_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "benchmarks = []\n",
    "if os.path.exists(json_path):\n",
    "    with open(json_path, 'r') as jsonfile:\n",
    "        tmp = json.load(jsonfile)\n",
    "        for values in tmp:\n",
    "            benchmarks.append(Benchmark.fromJson(values))\n",
    "else:\n",
    "    with open(json_path, 'w') as jsonfile:\n",
    "        json.dump([], jsonfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_best_ESN1(hp):\n",
    "    tmp_model = ESN1(units=hp.Int('units', min_value=50, max_value=MAX_UNITS),\n",
    "                     connectivity=hp.Float('connectivity 0',  min_value=0.0, max_value=1.),\n",
    "                     output_units=output_units,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=hp.Float('spectral radius', min_value=0.01, max_value=2., sampling='log'),\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1))\n",
    "\n",
    "    alpha = hp.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "def build_best_ESN2(hp):\n",
    "    global_sr = hp.Boolean('global spectral radius')\n",
    "    if global_sr:\n",
    "        sr = hp.Float('spectral radius', min_value=0.01, max_value=2., sampling='log', parent_name='global spectral radius', parent_values=True)\n",
    "    else:\n",
    "        sr = [hp.Float('spectral radius ' + str(i), min_value=0.01, max_value=2., sampling='log', parent_name='global spectral radius', parent_values=False)\n",
    "              for i in range(features)]\n",
    "\n",
    "    connectivity = [hp.Float('connectivity ' + str(i), min_value=0.0, max_value=1.) for i in range(features)]\n",
    "\n",
    "    tmp_model = ESN2(units=hp.Int('units', min_value=50, max_value=MAX_UNITS),\n",
    "                     sub_reservoirs=features,\n",
    "                     output_units=output_units,\n",
    "                     connectivity=connectivity,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=sr,\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                     global_sr=global_sr)\n",
    "\n",
    "    alpha = hp.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "def build_best_ESN3(hp):\n",
    "    global_sr = hp.Boolean('global spectral radius')\n",
    "    if global_sr:\n",
    "        sr = hp.Float('spectral radius', min_value=0.01, max_value=2., sampling='log', parent_name='global spectral radius', parent_values=True)\n",
    "    else:\n",
    "        sr = [hp.Float('spectral radius ' + str(i), min_value=0.01, max_value=2., sampling='log', parent_name='global spectral radius', parent_values=False)\n",
    "              for i in range(features)]\n",
    "\n",
    "    connectivity = [[hp.Float('connectivity ' + str(i), min_value=0.0, max_value=1.) if i == j else\n",
    "                     hp.Float('connectivity ' + str(i) + '->' + str(j), min_value=0.0, max_value=1.)\n",
    "                     for i in range(features)]\n",
    "                     for j in range(features)]\n",
    "\n",
    "    tmp_model = ESN3(units=hp.Int('units', min_value=50, max_value=MAX_UNITS),\n",
    "                     sub_reservoirs=features,\n",
    "                     connectivity=connectivity,\n",
    "                     output_units=output_units,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=sr,\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1., step=0.1),\n",
    "                     global_sr=global_sr)\n",
    "\n",
    "    alpha = hp.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "def build_best_ESN4(hp):\n",
    "    global_sr = hp.Boolean('global spectral radius')\n",
    "    if global_sr:\n",
    "        sr = hp.Float('spectral radius', min_value=0.01, max_value=2., sampling='log', parent_name='global spectral radius', parent_values=True)\n",
    "    else:\n",
    "        sr = [hp.Float('spectral radius ' + str(i), min_value=0.01, max_value=2., sampling='log', parent_name='global spectral radius', parent_values=False)\n",
    "              for i in range(features)]\n",
    "\n",
    "    connectivity = [[hp.Float('connectivity ' + str(i), min_value=0.0, max_value=1.) if i == j else\n",
    "                     hp.Float('connectivity ' + str(i) + '->' + str(j), min_value=0.0, max_value=1)\n",
    "                     for i in range(features)]\n",
    "                     for j in range(features)]\n",
    "\n",
    "    partitions = [hp.Float('partition ' + str(i), min_value=0., max_value=1.0) for i in range(features)]\n",
    "    total = sum(partitions)\n",
    "    partitions = list(map(lambda _x: 0 if total == 0 else _x / total, partitions))  # Normalize the partition vector now sum(partitions) == 1.\n",
    "\n",
    "    tmp_model = ESN4(units=hp.Int('units', min_value=50, max_value=MAX_UNITS),\n",
    "                     sub_reservoirs=features,\n",
    "                     partitions=partitions,\n",
    "                     connectivity=connectivity,\n",
    "                     output_units=output_units,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=sr,\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                     global_sr=global_sr)\n",
    "\n",
    "    alpha = hp.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "best_models = {\n",
    "    #'ESN1': build_best_ESN1,\n",
    "    'ESN2': build_best_ESN2,\n",
    "    #'ESN3': build_best_ESN3,\n",
    "    #'ESN4': build_best_ESN4,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find best models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.2666666805744171\n",
      "\n",
      "Best val_accuracy So Far: 0.5166666507720947\n",
      "Total elapsed time: 00h 03m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 845us/step - loss: 2.0821 - accuracy: 0.3833\n",
      "6/6 [==============================] - 0s 492us/step - loss: 2.2826 - accuracy: 0.2167\n",
      "6/6 [==============================] - 0s 870us/step - loss: 1.7552 - accuracy: 0.4000\n",
      "6/6 [==============================] - 0s 472us/step - loss: 2.3291 - accuracy: 0.2278\n",
      "6/6 [==============================] - 0s 795us/step - loss: 1.8520 - accuracy: 0.3833\n",
      "6/6 [==============================] - 0s 672us/step - loss: 1.6190 - accuracy: 0.4389\n",
      "6/6 [==============================] - 0s 473us/step - loss: 1.6417 - accuracy: 0.4944\n",
      "6/6 [==============================] - 0s 879us/step - loss: 1.9470 - accuracy: 0.4000\n",
      "6/6 [==============================] - 0s 609us/step - loss: 2.3323 - accuracy: 0.2500\n",
      "6/6 [==============================] - 0s 587us/step - loss: 1.6008 - accuracy: 0.4667\n",
      "Not already present in benchmarks. Adding...\n",
      "     Model : ESN2\n",
      "Experiment : Best\n",
      "  Accuracy : 36.61±9.47 %\n",
      "      Loss : 1.94±0.28\n",
      "Build time : 2.71±0.47s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "exp_name = \"Best\"\n",
    "\n",
    "for model_name, build_fn in best_models.items():\n",
    "    if is_benchmarked(benchmarks, model_name, exp_name) and SKIP:\n",
    "            continue\n",
    "    tf.random.set_seed(42)\n",
    "    model = tune_and_test(model_name, build_fn, exp_name, train_set, val_set, test_set,\n",
    "                          EPOCHS, PATIENCE, GUESSES,\n",
    "                          benchmarks, tuner_path=tuner_path)\n",
    "\n",
    "    model.plot(model_name, exp_name, path=weight_path, show=False)\n",
    "send_notification(\"Best is done\", \"All model done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESN1 best 1641151163\n",
      "ESN2 best 1641151447\n",
      "ESN3 best 1641151725\n",
      "ESN4 best 1641151991\n",
      "ESN1 Units 50 Connectivity 1 1641152227\n",
      "ESN2 Units 50 Connectivity 1 1641152467\n",
      "ESN3 Units 50 Connectivity 1 1641152715\n",
      "ESN4 Units 50 Connectivity 1 1641152973\n",
      "ESN1 Units 75 Connectivity 1 1641153222\n",
      "ESN2 Units 75 Connectivity 1 1641153495\n",
      "ESN3 Units 75 Connectivity 1 1641153755\n",
      "ESN4 Units 75 Connectivity 1 1641154006\n",
      "ESN1 Units 112 Connectivity 1 1641154249\n",
      "ESN2 Units 112 Connectivity 1 1641154502\n",
      "ESN3 Units 112 Connectivity 1 1641154754\n",
      "ESN4 Units 112 Connectivity 1 1641155010\n",
      "ESN1 Units 168 Connectivity 1 1641155283\n",
      "ESN2 Units 168 Connectivity 1 1641155556\n",
      "ESN3 Units 168 Connectivity 1 1641155822\n",
      "ESN4 Units 168 Connectivity 1 1641156076\n",
      "ESN1 Units 253 Connectivity 1 1641156329\n",
      "ESN2 Units 253 Connectivity 1 1641156608\n",
      "ESN3 Units 253 Connectivity 1 1641156894\n",
      "ESN4 Units 253 Connectivity 1 1641157176\n",
      "ESN1 Units 379 Connectivity 1 1641157465\n",
      "ESN2 Units 379 Connectivity 1 1641157801\n",
      "ESN3 Units 379 Connectivity 1 1641158152\n",
      "ESN4 Units 379 Connectivity 1 1641158476\n",
      "ESN2 Best 1641396277\n"
     ]
    }
   ],
   "source": [
    "for b in benchmarks:\n",
    "    print(b.model, b.experiment, b.timestamp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find best hyperparameters for each model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_ESN1(units, _, hp):\n",
    "    units = hp.Fixed('units', units)\n",
    "    hp.Fixed('global spectral radius', True)\n",
    "\n",
    "    tmp_model = ESN1(units=units,\n",
    "                     connectivity=hp.Fixed('connectivity 0', 1.),\n",
    "                     output_units=output_units,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=hp.Float('spectral radius', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1))\n",
    "\n",
    "    alpha = hp.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN2(units, global_sr, hp):\n",
    "    units = hp.Fixed('units', units)\n",
    "    global_sr = hp.Boolean('global spectral radius')\n",
    "    connectivity = [hp.Fixed('connectivity ' + str(i), 1.) for i in range(features)]\n",
    "\n",
    "    tmp_model = ESN2(units=units,\n",
    "                     sub_reservoirs=features,\n",
    "                     connectivity=connectivity,\n",
    "                     output_units=output_units,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=hp.Float('spectral radius', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                     global_sr=global_sr)\n",
    "\n",
    "    alpha = hp.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN3(units, global_sr, hp):\n",
    "    units = hp.Fixed('units', units)\n",
    "    global_sr = hp.Boolean('global spectral radius')\n",
    "\n",
    "    connectivity = [[hp.Fixed('connectivity ' + str(i), 1.) if i == j else\n",
    "                     hp.Float('connectivity ' + str(i) + '->' + str(j), min_value=0.0, max_value=1.)\n",
    "                     for i in range(features)]\n",
    "                     for j in range(features)]\n",
    "\n",
    "    tmp_model = ESN3(units=units,\n",
    "                     sub_reservoirs=features,\n",
    "                     connectivity=connectivity,\n",
    "                     output_units=output_units,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=hp.Float('spectral_radius', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                     global_sr=global_sr)\n",
    "\n",
    "    alpha = hp.Float('learning_rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "\n",
    "def build_ESN4(units, global_sr, hp):\n",
    "    units = hp.Fixed('units', units)\n",
    "    connectivity = [[hp.Fixed('connectivity ' + str(i), 1.) if i == j else\n",
    "                     hp.Float('connectivity ' + str(i) + '->' + str(j), min_value=0.0, max_value=1)\n",
    "                    for i in range(features)]\n",
    "                   for j in range(features)]\n",
    "\n",
    "    partitions = [hp.Float('partition ' + str(i), min_value=0., max_value=1.0) for i in range(features)]\n",
    "    total = sum(partitions)\n",
    "    partitions = list(map(lambda _x: 0 if total == 0 else _x / total, partitions))  # Normalize the partition vector now sum(partitions) == 1.\n",
    "\n",
    "    tmp_model = ESN4(units=units,\n",
    "                     sub_reservoirs=features,\n",
    "                     partitions=partitions,\n",
    "                     connectivity=connectivity,\n",
    "                     output_units=output_units,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=hp.Float('spectral radius', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                     global_sr=hp.Boolean('global spectral radius'))\n",
    "\n",
    "    alpha = hp.Float('learning rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN1 Units 50 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN1 Units 50 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 933us/step - loss: 2.3747 - accuracy: 0.2278\n",
      "6/6 [==============================] - 0s 886us/step - loss: 2.6558 - accuracy: 0.1611\n",
      "6/6 [==============================] - 0s 472us/step - loss: 2.2273 - accuracy: 0.3556\n",
      "6/6 [==============================] - 0s 520us/step - loss: 2.3091 - accuracy: 0.3056\n",
      "6/6 [==============================] - 0s 543us/step - loss: 2.2842 - accuracy: 0.3389\n",
      "6/6 [==============================] - 0s 497us/step - loss: 1.9462 - accuracy: 0.4389\n",
      "6/6 [==============================] - 0s 527us/step - loss: 1.9981 - accuracy: 0.4056\n",
      "6/6 [==============================] - 0s 601us/step - loss: 2.3189 - accuracy: 0.1944\n",
      "6/6 [==============================] - 0s 956us/step - loss: 2.1183 - accuracy: 0.3833\n",
      "6/6 [==============================] - 0s 956us/step - loss: 2.4176 - accuracy: 0.2778\n",
      "Already present. Overwriting..\n",
      "     Model : ESN1\n",
      "Experiment : Units 50 Connectivity 1\n",
      "  Accuracy : 30.89±8.80 %\n",
      "      Loss : 2.27±0.20\n",
      "Build time : 0.81±0.19s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN2 Units 50 Connectivity 1 hyperband/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/tesi/lib/models.py:127: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN2 Units 50 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 989us/step - loss: 1.9615 - accuracy: 0.3667\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.9411 - accuracy: 0.3389\n",
      "6/6 [==============================] - 0s 472us/step - loss: 2.2652 - accuracy: 0.3000\n",
      "6/6 [==============================] - 0s 556us/step - loss: 2.2303 - accuracy: 0.2722\n",
      "6/6 [==============================] - 0s 707us/step - loss: 1.9596 - accuracy: 0.3611\n",
      "6/6 [==============================] - 0s 856us/step - loss: 2.2303 - accuracy: 0.2722\n",
      "6/6 [==============================] - 0s 484us/step - loss: 2.2519 - accuracy: 0.3000\n",
      "6/6 [==============================] - 0s 579us/step - loss: 2.1226 - accuracy: 0.3167\n",
      "6/6 [==============================] - 0s 718us/step - loss: 2.0842 - accuracy: 0.3389\n",
      "6/6 [==============================] - 0s 446us/step - loss: 2.4678 - accuracy: 0.2000\n",
      "Already present. Overwriting..\n",
      "     Model : ESN2\n",
      "Experiment : Units 50 Connectivity 1\n",
      "  Accuracy : 30.67±4.75 %\n",
      "      Loss : 2.15±0.16\n",
      "Build time : 2.66±0.62s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN3 Units 50 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN3 Units 50 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 923us/step - loss: 1.9184 - accuracy: 0.3278\n",
      "6/6 [==============================] - 0s 920us/step - loss: 1.9031 - accuracy: 0.4056\n",
      "6/6 [==============================] - 0s 903us/step - loss: 1.7865 - accuracy: 0.4444\n",
      "6/6 [==============================] - 0s 503us/step - loss: 2.3040 - accuracy: 0.2111\n",
      "6/6 [==============================] - 0s 843us/step - loss: 1.6351 - accuracy: 0.4722\n",
      "6/6 [==============================] - 0s 857us/step - loss: 2.1271 - accuracy: 0.2722\n",
      "6/6 [==============================] - 0s 553us/step - loss: 1.8802 - accuracy: 0.4167\n",
      "6/6 [==============================] - 0s 750us/step - loss: 1.6274 - accuracy: 0.4778\n",
      "6/6 [==============================] - 0s 438us/step - loss: 1.8712 - accuracy: 0.4000\n",
      "6/6 [==============================] - 0s 902us/step - loss: 1.7856 - accuracy: 0.4333\n",
      "Already present. Overwriting..\n",
      "     Model : ESN3\n",
      "Experiment : Units 50 Connectivity 1\n",
      "  Accuracy : 38.61±8.36 %\n",
      "      Loss : 1.88±0.20\n",
      "Build time : 1.78±0.32s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN4 Units 50 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN4 Units 50 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 874us/step - loss: 2.1646 - accuracy: 0.3056\n",
      "6/6 [==============================] - 0s 822us/step - loss: 2.0743 - accuracy: 0.3778\n",
      "6/6 [==============================] - 0s 852us/step - loss: 2.1319 - accuracy: 0.4056\n",
      "6/6 [==============================] - 0s 502us/step - loss: 1.9567 - accuracy: 0.4333\n",
      "6/6 [==============================] - 0s 450us/step - loss: 1.9756 - accuracy: 0.4389\n",
      "6/6 [==============================] - 0s 520us/step - loss: 2.0611 - accuracy: 0.3778\n",
      "6/6 [==============================] - 0s 792us/step - loss: 2.0385 - accuracy: 0.3833\n",
      "6/6 [==============================] - 0s 849us/step - loss: 2.2328 - accuracy: 0.3167\n",
      "6/6 [==============================] - 0s 431us/step - loss: 2.2230 - accuracy: 0.3000\n",
      "6/6 [==============================] - 0s 832us/step - loss: 2.2249 - accuracy: 0.3333\n",
      "Already present. Overwriting..\n",
      "     Model : ESN4\n",
      "Experiment : Units 50 Connectivity 1\n",
      "  Accuracy : 36.72±4.85 %\n",
      "      Loss : 2.11±0.10\n",
      "Build time : 2.96±0.43s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN1 Units 75 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN1 Units 75 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 425us/step - loss: 1.8352 - accuracy: 0.3833\n",
      "6/6 [==============================] - 0s 870us/step - loss: 2.0615 - accuracy: 0.3056\n",
      "6/6 [==============================] - 0s 863us/step - loss: 1.8547 - accuracy: 0.3889\n",
      "6/6 [==============================] - 0s 572us/step - loss: 2.0053 - accuracy: 0.2778\n",
      "6/6 [==============================] - 0s 829us/step - loss: 1.8668 - accuracy: 0.3833\n",
      "6/6 [==============================] - 0s 459us/step - loss: 1.8709 - accuracy: 0.3889\n",
      "6/6 [==============================] - 0s 914us/step - loss: 1.7301 - accuracy: 0.4556\n",
      "6/6 [==============================] - 0s 495us/step - loss: 1.9505 - accuracy: 0.2778\n",
      "6/6 [==============================] - 0s 847us/step - loss: 1.9417 - accuracy: 0.3333\n",
      "6/6 [==============================] - 0s 879us/step - loss: 1.8808 - accuracy: 0.3667\n",
      "Already present. Overwriting..\n",
      "     Model : ESN1\n",
      "Experiment : Units 75 Connectivity 1\n",
      "  Accuracy : 35.61±5.38 %\n",
      "      Loss : 1.90±0.09\n",
      "Build time : 1.74±0.32s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN2 Units 75 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN2 Units 75 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 860us/step - loss: 2.0227 - accuracy: 0.4222\n",
      "6/6 [==============================] - 0s 882us/step - loss: 2.2354 - accuracy: 0.3278\n",
      "6/6 [==============================] - 0s 838us/step - loss: 2.0766 - accuracy: 0.3778\n",
      "6/6 [==============================] - 0s 495us/step - loss: 2.0164 - accuracy: 0.3944\n",
      "6/6 [==============================] - 0s 474us/step - loss: 1.9650 - accuracy: 0.4167\n",
      "6/6 [==============================] - 0s 410us/step - loss: 2.0519 - accuracy: 0.3778\n",
      "6/6 [==============================] - 0s 924us/step - loss: 1.9999 - accuracy: 0.4889\n",
      "6/6 [==============================] - 0s 859us/step - loss: 2.0528 - accuracy: 0.3611\n",
      "6/6 [==============================] - 0s 783us/step - loss: 1.8160 - accuracy: 0.4333\n",
      "6/6 [==============================] - 0s 857us/step - loss: 2.0486 - accuracy: 0.3611\n",
      "Already present. Overwriting..\n",
      "     Model : ESN2\n",
      "Experiment : Units 75 Connectivity 1\n",
      "  Accuracy : 39.61±4.35 %\n",
      "      Loss : 2.03±0.10\n",
      "Build time : 3.23±0.09s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN3 Units 75 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN3 Units 75 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 537us/step - loss: 2.0673 - accuracy: 0.3500\n",
      "6/6 [==============================] - 0s 613us/step - loss: 2.4268 - accuracy: 0.2556\n",
      "6/6 [==============================] - 0s 933us/step - loss: 1.8143 - accuracy: 0.4333\n",
      "6/6 [==============================] - 0s 479us/step - loss: 1.8943 - accuracy: 0.4444\n",
      "6/6 [==============================] - 0s 807us/step - loss: 2.3953 - accuracy: 0.2667\n",
      "6/6 [==============================] - 0s 493us/step - loss: 1.9616 - accuracy: 0.4389\n",
      "6/6 [==============================] - 0s 698us/step - loss: 2.0280 - accuracy: 0.3778\n",
      "6/6 [==============================] - 0s 849us/step - loss: 2.3951 - accuracy: 0.2333\n",
      "6/6 [==============================] - 0s 853us/step - loss: 2.2744 - accuracy: 0.2556\n",
      "6/6 [==============================] - 0s 874us/step - loss: 1.8475 - accuracy: 0.4944\n",
      "Already present. Overwriting..\n",
      "     Model : ESN3\n",
      "Experiment : Units 75 Connectivity 1\n",
      "  Accuracy : 35.50±9.14 %\n",
      "      Loss : 2.11±0.23\n",
      "Build time : 2.66±0.74s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN4 Units 75 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN4 Units 75 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 574us/step - loss: 2.4048 - accuracy: 0.2333\n",
      "6/6 [==============================] - 0s 716us/step - loss: 2.0257 - accuracy: 0.4556\n",
      "6/6 [==============================] - 0s 542us/step - loss: 2.1430 - accuracy: 0.3500\n",
      "6/6 [==============================] - 0s 952us/step - loss: 2.1938 - accuracy: 0.4222\n",
      "6/6 [==============================] - 0s 711us/step - loss: 1.9843 - accuracy: 0.3889\n",
      "6/6 [==============================] - 0s 557us/step - loss: 2.3023 - accuracy: 0.3167\n",
      "6/6 [==============================] - 0s 899us/step - loss: 1.9408 - accuracy: 0.3889\n",
      "6/6 [==============================] - 0s 952us/step - loss: 2.2943 - accuracy: 0.2167\n",
      "6/6 [==============================] - 0s 552us/step - loss: 2.0794 - accuracy: 0.4000\n",
      "6/6 [==============================] - 0s 826us/step - loss: 2.1927 - accuracy: 0.3556\n",
      "Already present. Overwriting..\n",
      "     Model : ESN4\n",
      "Experiment : Units 75 Connectivity 1\n",
      "  Accuracy : 35.28±7.37 %\n",
      "      Loss : 2.16±0.14\n",
      "Build time : 1.50±0.44s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN1 Units 112 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN1 Units 112 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 556us/step - loss: 2.6150 - accuracy: 0.2222\n",
      "6/6 [==============================] - 0s 875us/step - loss: 2.2966 - accuracy: 0.2333\n",
      "6/6 [==============================] - 0s 890us/step - loss: 2.0498 - accuracy: 0.4722\n",
      "6/6 [==============================] - 0s 741us/step - loss: 2.0437 - accuracy: 0.4667\n",
      "6/6 [==============================] - 0s 538us/step - loss: 2.2727 - accuracy: 0.2556\n",
      "6/6 [==============================] - 0s 495us/step - loss: 2.4639 - accuracy: 0.2056\n",
      "6/6 [==============================] - 0s 552us/step - loss: 2.1442 - accuracy: 0.3333\n",
      "6/6 [==============================] - 0s 705us/step - loss: 2.5446 - accuracy: 0.2222\n",
      "6/6 [==============================] - 0s 534us/step - loss: 2.0122 - accuracy: 0.4222\n",
      "6/6 [==============================] - 0s 578us/step - loss: 2.3959 - accuracy: 0.2889\n",
      "Already present. Overwriting..\n",
      "     Model : ESN1\n",
      "Experiment : Units 112 Connectivity 1\n",
      "  Accuracy : 31.22±9.98 %\n",
      "      Loss : 2.28±0.21\n",
      "Build time : 0.70±0.15s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN2 Units 112 Connectivity 1 hyperband/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN2 Units 112 Connectivity 1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 10 benchmarks:\n",
      "6/6 [==============================] - 0s 675us/step - loss: 1.7632 - accuracy: 0.4167\n",
      "6/6 [==============================] - 0s 854us/step - loss: 1.8480 - accuracy: 0.4278\n",
      "6/6 [==============================] - 0s 476us/step - loss: 1.7387 - accuracy: 0.4278\n",
      "6/6 [==============================] - 0s 454us/step - loss: 1.8613 - accuracy: 0.4222\n",
      "6/6 [==============================] - 0s 527us/step - loss: 2.2156 - accuracy: 0.2556\n",
      "6/6 [==============================] - 0s 460us/step - loss: 1.6549 - accuracy: 0.4500\n",
      "6/6 [==============================] - 0s 506us/step - loss: 1.9562 - accuracy: 0.3889\n",
      "6/6 [==============================] - 0s 616us/step - loss: 1.6862 - accuracy: 0.4500\n",
      "6/6 [==============================] - 0s 814us/step - loss: 1.6769 - accuracy: 0.4667\n",
      "6/6 [==============================] - 0s 481us/step - loss: 1.8949 - accuracy: 0.4278\n",
      "Already present. Overwriting..\n",
      "     Model : ESN2\n",
      "Experiment : Units 112 Connectivity 1\n",
      "  Accuracy : 41.33±5.63 %\n",
      "      Loss : 1.83±0.16\n",
      "Build time : 1.09±0.22s\n",
      "\n",
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/Libras/ESN3 Units 112 Connectivity 1 hyperband/oracle.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_26299/1234459546.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_seed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m42\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0mbuild_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuild_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mfn_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtune_and_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuild_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPATIENCE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mGUESSES\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbenchmarks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuner_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtuner_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexp_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mweight_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/utility.py\u001B[0m in \u001B[0;36mtune_and_test\u001B[0;34m(model_name, build_model_fn, experiment_name, train_set, val_set, test_set, max_epochs, patience, guesses, benchmarks, tuner_path, tensorboard_path, benchmarks_verbose, notify)\u001B[0m\n\u001B[1;32m    110\u001B[0m     \u001B[0mx_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 112\u001B[0;31m     tuner = Hyperband(\n\u001B[0m\u001B[1;32m    113\u001B[0m         \u001B[0mbuild_model_fn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0mobjective\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'val_accuracy'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/tuners/hyperband.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001B[0m\n\u001B[1;32m    365\u001B[0m             \u001B[0mallow_new_entries\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mallow_new_entries\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m         )\n\u001B[0;32m--> 367\u001B[0;31m         super(Hyperband, self).__init__(\n\u001B[0m\u001B[1;32m    368\u001B[0m             \u001B[0moracle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moracle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhypermodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhypermodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    369\u001B[0m         )\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001B[0m\n\u001B[1;32m    109\u001B[0m             )\n\u001B[1;32m    110\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m         super(Tuner, self).__init__(\n\u001B[0m\u001B[1;32m    112\u001B[0m             \u001B[0moracle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moracle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0mhypermodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhypermodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001B[0m\n\u001B[1;32m     80\u001B[0m             )\n\u001B[1;32m     81\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moracle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moracle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m         self.oracle._set_project_dir(\n\u001B[0m\u001B[1;32m     83\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproject_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverwrite\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m         )\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/oracle.py\u001B[0m in \u001B[0;36m_set_project_dir\u001B[0;34m(self, directory, project_name, overwrite)\u001B[0m\n\u001B[1;32m    351\u001B[0m                 )\n\u001B[1;32m    352\u001B[0m             )\n\u001B[0;32m--> 353\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    354\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras_tuner/engine/oracle.py\u001B[0m in \u001B[0;36mreload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    370\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mfname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrial_fnames\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    371\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 372\u001B[0;31m                 \u001B[0mtrial_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    373\u001B[0m             \u001B[0mtrial_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    374\u001B[0m             \u001B[0mtrial\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrial_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrial\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    121\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m       \u001B[0mlength\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 123\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_prepare_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_buf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlength\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m   @deprecation.deprecated_args(\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#  Units follow this rule units(x) = (1.5 ** x) * 50  for x in [0; 5]\n",
    "experiments = {\n",
    "    'Units 50 Connectivity 1': (50, None),\n",
    "    'Units 75 Connectivity 1': (75, None),\n",
    "    'Units 112 Connectivity 1': (122, None),\n",
    "    'Units 168 Connectivity 1': (168, None),\n",
    "    'Units 253 Connectivity 1': (253, None),\n",
    "    'Units 379 Connectivity 1': (379, None),\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'ESN1': build_ESN1,\n",
    "    'ESN2': build_ESN2,\n",
    "    'ESN3': build_ESN3,\n",
    "    'ESN4': build_ESN4,\n",
    "}\n",
    "\n",
    "for exp_name, fn_params in experiments.items():\n",
    "    for model_name, build_fn in models.items():\n",
    "        if is_benchmarked(benchmarks, model_name, exp_name) and SKIP:\n",
    "            continue\n",
    "        tf.random.set_seed(42)\n",
    "        build_fn = partial(build_fn, *fn_params)\n",
    "        model = tune_and_test(model_name, build_fn, exp_name, train_set, val_set, test_set, EPOCHS, PATIENCE, GUESSES, benchmarks, tuner_path=tuner_path)\n",
    "        model.plot(model_name, exp_name, path=weight_path)\n",
    "\n",
    "send_notification(\"Done\", \"All model done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BenchmarkEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, lib.utility.Benchmark):\n",
    "            return obj.toJson()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "with open(json_path, \"w\") as out_file:\n",
    "    json.dump(benchmarks, out_file, cls=BenchmarkEncoder, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}