{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import lib.models\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 14:58:28.581755: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-13 14:58:28.581784: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dir:  /dati/luca/Uni-Luca/Tesi/tesi/data/character trajectories\n",
      "tuner dir: /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/character trajectories\n",
      "tensorboard dir: /tmp/tensorboard/\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "import notify2\n",
    "notify2.init(\"Tesi.AI\")\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.getcwd() + os.sep + os.pardir)\n",
    "\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from lib.time_series_datasets import *\n",
    "from lib.models import *\n",
    "from lib.utility import plot_matrices\n",
    "\n",
    "PROJECT_NAME = \"character trajectories\"\n",
    "\n",
    "DATA_DIR = os.path.join(\"data\", PROJECT_NAME)\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, DATA_DIR)\n",
    "\n",
    "TUNER_DIR = os.path.join(\"models\", \"tuner\", PROJECT_NAME)\n",
    "TUNER_DIR = os.path.join(PROJECT_ROOT, TUNER_DIR)\n",
    "\n",
    "IMAGE_DIR = \"images\"\n",
    "IMAGE_DIR = os.path.join(PROJECT_ROOT, IMAGE_DIR)\n",
    "\n",
    "TB_DIR = os.path.abspath(os.sep) + \"tmp\" + os.sep + \"tensorboard\" + os.sep\n",
    "\n",
    "print(\"data dir: \", DATA_DIR)\n",
    "print(\"tuner dir:\", TUNER_DIR)\n",
    "print(\"tensorboard dir:\", TB_DIR)\n",
    "\n",
    "EPOCHS = 200\n",
    "GUESSES = 1\n",
    "PATIENCE = 10\n",
    "MAX_UNITS = 200\n",
    "\n",
    "#set the following values based on the specific dataset\n",
    "OUTPUT_UNITS = 20\n",
    "OUTPUT_ACTIVATION = tf.keras.activations.softmax  # https://www.tensorflow.org/api_docs/python/tf/keras/activations  'softmax'\n",
    "LOSS_FUNCTION =  tf.keras.losses.SparseCategoricalCrossentropy()  # https://www.tensorflow.org/api_docs/python/tf/keras/losses  'sparse_categorical_crossentropy'\n",
    "\n",
    "if not os.path.exists(TUNER_DIR):\n",
    "    os.makedirs(TUNER_DIR)\n",
    "if not os.path.exists(TB_DIR):\n",
    "    os.makedirs(TB_DIR)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/sktime/utils/data_io.py:63: FutureWarning: This function has moved to datasets/_data_io, this version will be removed in V0.10\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\n",
      "\tinput: (952, 180, 3)\n",
      "\toutput: (952,)\n",
      "Test shape:\n",
      "\tinput: (1436, 182, 3)\n",
      "\toutput: (1436,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = load_sktime_dataset(os.path.join(DATA_DIR, 'test.ts'))\n",
    "x_train_all, y_train_all = load_sktime_dataset(os.path.join(DATA_DIR, 'train.ts'))  # Max shape serve per avere il test set e il train set della stessa lunghezza\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, test_size=0.33, random_state=42)\n",
    "\n",
    "features = x_train.shape[-1]\n",
    "\n",
    "train_set = (x_train, y_train)\n",
    "val_set = (x_val, y_val)\n",
    "test_set = (x_test, y_test)\n",
    "\n",
    "benchmarks = {}\n",
    "print(\"Train shape:\\n\\tinput: {}\\n\\toutput: {}\\nTest shape:\\n\\tinput: {}\\n\\toutput: {}\\n\".format(x_train.shape, y_train.shape, x_test.shape, y_test.shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Type 1 ESN FullConnected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/character trajectories/ESN1 C1 hyperband/oracle.json\n",
      "USE bias: True\n",
      "Dtype:  float32\n",
      "INFO:tensorflow:Reloading Tuner from /dati/luca/Uni-Luca/Tesi/tesi/models/tuner/character trajectories/ESN1 C1 hyperband/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Start 1 benchmarks:\n",
      "USE bias: True\n",
      "Dtype:  float32\n",
      "Epoch 1/200\n",
      "30/30 [==============================] - 2s 49ms/step - loss: 2.8905 - accuracy: 0.2563 - val_loss: 1.9029 - val_accuracy: 0.4404\n",
      "Epoch 2/200\n",
      "29/30 [============================>.] - ETA: 0s - loss: 1.9080 - accuracy: 0.3955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_104386/4208362034.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtmp_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtune_and_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_set\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPATIENCE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mGUESSES\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbenchmarks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuner_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mTUNER_DIR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbenchmarks_verbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/utility.py\u001B[0m in \u001B[0;36mtune_and_test\u001B[0;34m(name, build_model_fn, train_set, val_set, test_set, max_epochs, patience, guesses, benchmarks, tuner_path, tensorboard_path, benchmarks_verbose)\u001B[0m\n\u001B[1;32m     76\u001B[0m         \u001B[0minitial_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m         \u001B[0mtest_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhypermodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbest_model_hp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m         test_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=max_epochs,\n\u001B[0m\u001B[1;32m     79\u001B[0m                        callbacks=callbacks, verbose=benchmarks_verbose)\n\u001B[1;32m     80\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/lib/models.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, **kwargs)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1214\u001B[0m                 _r=1):\n\u001B[1;32m   1215\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1216\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1217\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1218\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 910\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    911\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    912\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    940\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    941\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 942\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    943\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    944\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3128\u001B[0m       (graph_function,\n\u001B[1;32m   3129\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3130\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3131\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1957\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1958\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1959\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1960\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1961\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    596\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 598\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    599\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    600\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/dati/luca/Uni-Luca/Tesi/tesi/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     60\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_name = 'ESN1 C1'\n",
    "\n",
    "def build_model(hp):\n",
    "    tmp_model = lib.models.ESN1_SLOW(units=hp.Int('units', min_value=5, max_value=MAX_UNITS),\n",
    "                output_units=OUTPUT_UNITS,\n",
    "                output_activation=OUTPUT_ACTIVATION,\n",
    "                input_scaling=hp.Float('input_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                bias_scaling=hp.Float('bias_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                spectral_radius=hp.Float('spectral_radius', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                )\n",
    "    alpha = hp.Float('learning_rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "model = tune_and_test(model_name, build_model, train_set, val_set, test_set, EPOCHS, PATIENCE, GUESSES, benchmarks, tuner_path=TUNER_DIR, benchmarks_verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "units = model.units\n",
    "print(\"units: \", units)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_name = 'ESN2 C1'\n",
    "\n",
    "def build_model(hp):\n",
    "    tmp_model = ESN2(units=units,\n",
    "                     sub_reservoirs=features,\n",
    "                     output_units=OUTPUT_UNITS,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=hp.Float('spectral_radius', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                     )\n",
    "\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(\n",
    "            hp.Float('learning_rate', min_value=1e-5, max_value=1e-1, sampling='log')),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy'])\n",
    "    return tmp_model\n",
    "\n",
    "model = tune_and_test(model_name, build_model, train_set, val_set, test_set, EPOCHS, PATIENCE, TUNER_DIR, GUESSES)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_name = 'ESN3 C1'\n",
    "\n",
    "def build_model(hp):\n",
    "    connectivity = [[]]\n",
    "    for i in range(features):\n",
    "        for j in range(features):\n",
    "            if i == j:\n",
    "                connectivity[i][j] = 1\n",
    "            else:\n",
    "                connectivity[i][j] = hp.Float('conn '+str(i)+'-'+str(j), min_value=0.1, max_value=1)\n",
    "\n",
    "\n",
    "    tmp_model = ESN3(units=units,\n",
    "                     sub_reservoirs=features,\n",
    "                     connectivity=connectivity,\n",
    "                     output_units=OUTPUT_UNITS,\n",
    "                     output_activation=OUTPUT_ACTIVATION,\n",
    "                     input_scaling=hp.Float('input_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     bias_scaling=hp.Float('bias_scaling', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     spectral_radius=hp.Float('spectral_radius', min_value=0.1, max_value=1.5, step=0.1),\n",
    "                     leaky=hp.Float('leaky', min_value=0.1, max_value=1, step=0.1),\n",
    "                     )\n",
    "    alpha = hp.Float('learning_rate', min_value=1e-5, max_value=1e-1, sampling='log')\n",
    "    tmp_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(alpha),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return tmp_model\n",
    "\n",
    "model = tune_and_test(model_name, build_model, train_set, val_set, test_set, EPOCHS, PATIENCE, TUNER_DIR, GUESSES)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 [==============================] - 2s 47ms/step - loss: 83.6373 - accuracy: 0.1492 - val_loss: 50.7271 - val_accuracy: 0.1319\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 52.4721 - accuracy: 0.1712 - val_loss: 71.2787 - val_accuracy: 0.1426\n",
      "[<tf.Variable 'readout/kernel:0' shape=(168, 20) dtype=float32, numpy=\n",
      "array([[ 2.811297 ,  3.235911 ,  5.01888  , ...,  4.0138474,  3.9028633,\n",
      "         2.975837 ],\n",
      "       [ 2.5162125,  3.4989874,  4.780198 , ...,  3.6714506,  3.2605605,\n",
      "         3.3053272],\n",
      "       [ 2.6636488,  3.0830843,  2.9081244, ...,  3.110036 ,  4.6934934,\n",
      "         3.5236776],\n",
      "       ...,\n",
      "       [ 2.6906118,  2.8970194,  1.7279671, ...,  4.140754 ,  3.9719844,\n",
      "         3.0833235],\n",
      "       [-2.7536223, -2.7324097, -3.03714  , ..., -4.267496 , -3.9416988,\n",
      "        -3.0553265],\n",
      "       [-2.8317165, -2.9242358, -1.444787 , ..., -3.7799802, -3.8905382,\n",
      "        -3.0403194]], dtype=float32)>, <tf.Variable 'readout/bias:0' shape=(20,) dtype=float32, numpy=\n",
      "array([2.709212 , 3.1580288, 3.8663845, 3.552177 , 3.9195497, 3.448732 ,\n",
      "       2.5839565, 2.8841958, 2.9257247, 3.4578269, 4.0218287, 2.774078 ,\n",
      "       3.6072981, 3.0751724, 2.4923081, 2.959786 , 1.5383242, 3.5964222,\n",
      "       3.9075027, 3.0467165], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "kernel_init = Kernel(initializer=tf.keras.initializers.RandomUniform(minval=-1., maxval=1))\n",
    "recurrent_kernel_init = RecurrentFullConnected(0.4)\n",
    "bias_init = tf.keras.initializers.RandomUniform(minval=-0.3, maxval=0.3)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Masking(),\n",
    "    lib.esn.ESN(168, 0.5, kernel_initializer=kernel_init, recurrent_initializer=recurrent_kernel_init, bias_initializer=bias_init),\n",
    "    keras.layers.Dense(20, activation=OUTPUT_ACTIVATION, name=\"readout\")\n",
    "    ])\n",
    "\n",
    "model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(0.5),\n",
    "        loss=LOSS_FUNCTION,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=EPOCHS,\n",
    "callbacks=keras.callbacks.EarlyStopping(monitor='val_loss', patience = 1, restore_best_weights = True))\n",
    "\n",
    "print(model.trainable_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}